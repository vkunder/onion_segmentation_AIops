{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b82f2ea4",
   "metadata": {},
   "source": [
    "## with PreprocessMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93a5867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:33:00.668671: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-01 12:33:00.779345: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/agrograde/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2024-07-01 12:33:00.779366: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-01 12:33:00.803674: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-01 12:33:01.183543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/agrograde/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2024-07-01 12:33:01.183593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/agrograde/.local/lib/python3.8/site-packages/cv2/../../lib64:/opt/ros/noetic/lib\n",
      "2024-07-01 12:33:01.183599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/agrograde/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "import segmentation_models as sm\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.utils import generic_utils\n",
    "from segmentation_models.losses import CategoricalFocalLoss\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "# from keras.optimizers import Adam,SGD\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import MeanIoU\n",
    "from glob import glob\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.quantization.keras import QuantizeConfig\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67a48912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:33:02.605828: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-07-01 12:33:02.605860: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: agrograde-System-Product-Name\n",
      "2024-07-01 12:33:02.605866: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: agrograde-System-Product-Name\n",
      "2024-07-01 12:33:02.605980: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 535.183.1\n",
      "2024-07-01 12:33:02.606003: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 535.171.4\n",
      "2024-07-01 12:33:02.606009: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 535.171.4 does not match DSO version 535.183.1 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    " print('Num GPUs Available: ', len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9898e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessMasks(mask,height,width):\n",
    "    mask_resized = cv2.threshold(cv2.resize(mask, (height,width)), 50, 1, cv2.THRESH_BINARY)[1]\n",
    "    mask_data = np.zeros((height,width,2))\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "\n",
    "\n",
    "            #for segmentation mask\n",
    "            if mask_resized[i,j]> 0:\n",
    "                mask_data[i,j,1] = 1\n",
    "            else:\n",
    "                mask_data[i,j,0] = 1\n",
    "                \n",
    "    return mask_data       #output from the function(height, width, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549d6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    images = sorted(glob(os.path.join(image_path, 'images/*')))\n",
    "    sprout = sorted(glob(os.path.join(image_path, 'Sprout/*')))\n",
    "    peeled = sorted(glob(os.path.join(image_path, 'Peeled/*')))\n",
    "    rotten = sorted(glob(os.path.join(image_path, 'Rotten/*')))\n",
    "    double = sorted(glob(os.path.join(image_path, 'Double/*')))\n",
    "    background = sorted(glob(os.path.join(image_path, 'Background/*')))\n",
    "    return images,sprout,peeled,rotten,double,background\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6371d5e0-0a3d-4928-af78-6910121844b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/home/agrograde/Desktop/4th_mar/test_image_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21d4b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = '/home/agrograde/Desktop/4th_mar/test_image_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdeff04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images,sprout,peeled,rotten,double,background = load_data(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "340a3532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(sprout))\n",
    "print(len(peeled))\n",
    "print(len(rotten))\n",
    "print(len(double))\n",
    "print(len(background))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3816cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    \n",
    "    x = cv2.imread(path)\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba1b202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = preprocessMasks(x, 224, 224)\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d4ac0f-52c1-4303-900b-1c0c19a2672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_sample(image_path, mask_paths):\n",
    "#     image = read_image(image_path)\n",
    "#     masks = [read_mask(mask_path)[:, :, 1] for mask_path in mask_paths]\n",
    "    \n",
    "#     plt.figure(figsize=(20, 10))\n",
    "    \n",
    "#     plt.subplot(1, 6, 1)\n",
    "#     plt.imshow(image.astype(np.uint8))\n",
    "#     plt.title('Image')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     titles = ['Sprout Mask', 'Peeled Mask', 'Rotten Mask', 'Double Mask', 'Background Mask']\n",
    "#     for i, mask in enumerate(masks):\n",
    "#         plt.subplot(1, 6, i + 2)\n",
    "#         plt.imshow(mask, cmap='gray')\n",
    "#         plt.title(titles[i])\n",
    "#         plt.axis('off')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Visualize a few samples to ensure correct pairing\n",
    "# for i in range(5):\n",
    "#     visualize_sample(images[i], [sprout[i], peeled[i], rotten[i], double[i], background[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b064af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = read_image(images[0])\n",
    "# y1 = read_mask(sprout[0])\n",
    "# y2 = read_mask(peeled[0])\n",
    "# y3 = read_mask(rotten[0])\n",
    "# y4 = read_mask(double[0])\n",
    "# y5 = read_mask(background[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "922618ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x.shape,y1.shape,y2.shape,y3.shape,y4.shape,y5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3bbbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(x,y1,y2,y3,y4,y5):\n",
    "#     def f(x,y1,y2,y3,y4,y5):\n",
    "#         x = x.decode()\n",
    "#         y1 = y1.decode()\n",
    "#         y2 = y2.decode()\n",
    "#         y3 = y3.decode()\n",
    "#         y4 = y4.decode()\n",
    "#         y5 = y5.decode()\n",
    "        \n",
    "#         x = read_image(x)\n",
    "#         y1 = read_mask(y1)\n",
    "#         y2 = read_mask(y2)\n",
    "#         y3 = read_mask(y3)\n",
    "#         y4 = read_mask(y4)\n",
    "#         y5 = read_mask(y5)\n",
    "        \n",
    "#         return x,y1,y2,y3,y4,y5\n",
    "    \n",
    "#     images, sprout, peeled, rotten,double,background = tf.numpy_function(f, [x,y1,y2,y3,y4,y5], [tf.float32, tf.float32,tf.float32,tf.float32,tf.float32,tf.float32])\n",
    "#     images.set_shape([224, 224, 3])\n",
    "#     sprout.set_shape([224, 224, 2])\n",
    "#     peeled.set_shape([224, 224, 2])\n",
    "#     rotten.set_shape([224, 224, 2])\n",
    "#     double.set_shape([224, 224, 2])\n",
    "#     background.set_shape([224, 224, 2])\n",
    "\n",
    "#     return images, sprout, peeled, rotten,double, background\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59d9973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y1, y2, y3, y4, y5):\n",
    "    def f(x, y1, y2, y3, y4, y5):\n",
    "        x = x.decode()\n",
    "        y1 = y1.decode()\n",
    "        y2 = y2.decode()\n",
    "        y3 = y3.decode()\n",
    "        y4 = y4.decode()\n",
    "        y5 = y5.decode()\n",
    "        \n",
    "        x = read_image(x)\n",
    "        y1 = read_mask(y1)\n",
    "        y2 = read_mask(y2)\n",
    "        y3 = read_mask(y3)\n",
    "        y4 = read_mask(y4)\n",
    "        y5 = read_mask(y5)\n",
    "        \n",
    "        return x, y1, y2, y3, y4, y5\n",
    "    \n",
    "    images, sprout, peeled, rotten, double, background = tf.numpy_function(\n",
    "        f, [x, y1, y2, y3, y4, y5], \n",
    "        [tf.float32, tf.float32, tf.float32, tf.float32, tf.float32, tf.float32]\n",
    "    )\n",
    "    \n",
    "    images.set_shape([224, 224, 3])\n",
    "    sprout.set_shape([224, 224, 2])\n",
    "    peeled.set_shape([224, 224, 2])\n",
    "    rotten.set_shape([224, 224, 2])\n",
    "    double.set_shape([224, 224, 2])\n",
    "    background.set_shape([224, 224, 2])\n",
    "\n",
    "    return images, sprout, peeled, rotten, double, background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb2befee-2a76-4ec4-8965-ea0a911132e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:33:07.589510: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def tf_dataset(x, y1, y2, y3, y4, y5, batch_size, train_split=0.8, val_split=0.1):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y1, y2, y3, y4, y5))\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    total_samples = len(x)\n",
    "    train_samples = int(total_samples * train_split)\n",
    "    val_samples = int(total_samples * val_split)\n",
    "    \n",
    "    dataset = dataset.shuffle(buffer_size=total_samples, reshuffle_each_iteration=True)\n",
    "    \n",
    "    train_dataset = dataset.take(train_samples).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = dataset.skip(train_samples).take(val_samples).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "(train_dataset, val_dataset) = tf_dataset(images, sprout, peeled, rotten, double, background, batch_size=16, \n",
    "                                           train_split=0.8, val_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb3a43b5-7681-4f54-8c9c-4dc65e9cc92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tf_dataset(x, y1, y2, y3, y4, y5, batch_size, train_split=0.8, val_split=0.1):\n",
    "#     # Combine inputs and targets into a single dataset\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((x, y1, y2, y3, y4, y5))\n",
    "#     dataset = dataset.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#     # Calculate the number of samples for each split\n",
    "#     total_samples = len(x)\n",
    "#     train_samples = int(total_samples * train_split)\n",
    "#     val_samples = int(total_samples * val_split)\n",
    "\n",
    "#     dataset = dataset.shuffle(buffer_size=total_samples, reshuffle_each_iteration=True)\n",
    "    \n",
    "#     train_dataset = dataset.take(train_samples).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "#     val_dataset = dataset.skip(train_samples).take(val_samples).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "#     # Split inputs and targets into separate datasets\n",
    "#     train_images = train_dataset.map(lambda x, *y: x)\n",
    "#     train_sprout = train_dataset.map(lambda x, *y: y[0])\n",
    "#     train_peeled = train_dataset.map(lambda x, *y: y[1])\n",
    "#     train_rotten = train_dataset.map(lambda x, *y: y[2])\n",
    "#     train_double = train_dataset.map(lambda x, *y: y[3])\n",
    "#     train_background = train_dataset.map(lambda x, *y: y[4])\n",
    "    \n",
    "#     # For validation dataset\n",
    "#     val_images = val_dataset.map(lambda x, *y: x)\n",
    "#     val_sprout = val_dataset.map(lambda x, *y: y[0])\n",
    "#     val_peeled = val_dataset.map(lambda x, *y: y[1])\n",
    "#     val_rotten = val_dataset.map(lambda x, *y: y[2])\n",
    "#     val_double = val_dataset.map(lambda x, *y: y[3])\n",
    "#     val_background = val_dataset.map(lambda x, *y: y[4])\n",
    "    \n",
    "#     # Batch the datasets\n",
    "#     train_images = train_images.batch(batch_size)\n",
    "#     train_sprout = train_sprout.batch(batch_size)\n",
    "#     train_peeled = train_peeled.batch(batch_size)\n",
    "#     train_rotten = train_rotten.batch(batch_size)\n",
    "#     train_double = train_double.batch(batch_size)\n",
    "#     train_background = train_background.batch(batch_size)\n",
    "    \n",
    "#     val_images = val_images.batch(batch_size)\n",
    "#     val_sprout = val_sprout.batch(batch_size)\n",
    "#     val_peeled = val_peeled.batch(batch_size)\n",
    "#     val_rotten = val_rotten.batch(batch_size)\n",
    "#     val_double = val_double.batch(batch_size)\n",
    "#     val_background = val_background.batch(batch_size)\n",
    "    \n",
    "#     # Prefetch data for improved performance\n",
    "#     train_images = train_images.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     train_sprout = train_sprout.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     train_peeled = train_peeled.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     train_rotten = train_rotten.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     train_double = train_double.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     train_background = train_background.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "#     val_images = val_images.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     val_sprout = val_sprout.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     val_peeled = val_peeled.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     val_rotten = val_rotten.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     val_double = val_double.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     val_background = val_background.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "#     return (train_images, train_sprout, train_peeled, train_rotten, train_double, train_background), \\\n",
    "#            (val_images, val_sprout, val_peeled, val_rotten, val_double, val_background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b11550-68ab-455d-ac09-70c26de0f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def visualize_batch(images_batch, masks_batch, batch_size=16):\n",
    "#     plt.figure(figsize=(20, 20))\n",
    "    \n",
    "#     for i in range(batch_size):\n",
    "#         img = images_batch[i]\n",
    "#         mask_sprout = masks_batch[0][i][:, :, 1]\n",
    "#         mask_peeled = masks_batch[1][i][:, :, 1]\n",
    "#         mask_rotten = masks_batch[2][i][:, :, 1]\n",
    "#         mask_double = masks_batch[3][i][:, :, 1]\n",
    "#         mask_background = masks_batch[4][i][:, :, 1]\n",
    "        \n",
    "#         plt.subplot(batch_size, 6, i*6 + 1)\n",
    "#         plt.imshow(img.astype(np.uint8))\n",
    "#         plt.title('Image')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(batch_size, 6, i*6 + 2)\n",
    "#         plt.imshow(mask_sprout, cmap='gray')\n",
    "#         plt.title('Sprout Mask')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(batch_size, 6, i*6 + 3)\n",
    "#         plt.imshow(mask_peeled, cmap='gray')\n",
    "#         plt.title('Peeled Mask')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(batch_size, 6, i*6 + 4)\n",
    "#         plt.imshow(mask_rotten, cmap='gray')\n",
    "#         plt.title('Rotten Mask')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(batch_size, 6, i*6 + 5)\n",
    "#         plt.imshow(mask_double, cmap='gray')\n",
    "#         plt.title('Double Mask')\n",
    "#         plt.axis('off')\n",
    "        \n",
    "#         plt.subplot(batch_size, 6, i*6 + 6)\n",
    "#         plt.imshow(mask_background, cmap='gray')\n",
    "#         plt.title('Background Mask')\n",
    "#         plt.axis('off')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c8bd029-8b1d-414c-b3d7-be5aa56a8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize a batch after shuffling\n",
    "# for batch in train_dataset.take(1):\n",
    "#     images_batch, masks_batches = batch[0].numpy(), [batch[i].numpy() for i in range(1, 6)]\n",
    "\n",
    "# visualize_batch(images_batch, masks_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48782ca5-20fb-4e6e-afaf-16e886a4d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_datasets(train_dataset, val_dataset):\n",
    "    def map_fn(images, sprout, peeled, rotten, double, background):\n",
    "        labels_dict = {\n",
    "            \"sprout\": sprout,\n",
    "            \"peeled\": peeled,\n",
    "            \"rotten\": rotten,\n",
    "            \"double\": double,\n",
    "            \"background\": background\n",
    "        }\n",
    "        return images, labels_dict\n",
    "\n",
    "    train_data = train_dataset.map(map_fn)\n",
    "    val_data = val_dataset.map(map_fn)\n",
    "\n",
    "    return train_data, val_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d952296-bfe0-49ff-b418-712489c6feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = create_dict_datasets(train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bf78e0-d302-422f-a325-ebc6c1246d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51dceb9f-490e-4a55-9536-ad13457a2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_data.take(1):\n",
    "#     images_batch, masks_dict_batch = batch[0].numpy(), {k: v.numpy() for k, v in batch[1].items()}\n",
    "\n",
    "# visualize_batch(images_batch, masks_dict_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68683090-1af9-46e3-9144-ef674ccfb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main utility functions for model\n",
    "def dsc(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dsc(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def iou_score(gt, pr, class_weights=1., smooth=1, per_image=True, threshold=None):\n",
    "    '''\n",
    "    input：\n",
    "        gt: ground truth 4D keras tensor (B, H, W, C)\n",
    "        pr: prediction 4D keras tensor (B, H, W, C)\n",
    "        class_weights: 1. or list of class weights, len(weights) = C\n",
    "        smooth: value to avoid division by zero\n",
    "        per_image: if ``True``, metric is calculated as mean over images in batch (B),\n",
    "            else over whole batch\n",
    "        threshold: value to round predictions (use ``>`` comparison), \n",
    "        if ``None`` prediction prediction will not be round\n",
    "    output：\n",
    "        IoU/Jaccard score in range [0, 1]\n",
    "    '''\n",
    "    if per_image:\n",
    "        axes = [1, 2]\n",
    "    else:\n",
    "        axes = [0, 1, 2]\n",
    "        \n",
    "    if threshold is not None:\n",
    "        pr = tf.greater(pr, threshold)\n",
    "        pr = tf.cast(pr, dtype=tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(gt * pr, axis=axes)\n",
    "    union = tf.reduce_sum(gt + pr, axis=axes) - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "\n",
    "    # mean per image\n",
    "    if per_image:\n",
    "        iou = tf.reduce_mean(iou, axis=0)\n",
    "\n",
    "    # weighted mean per class\n",
    "    iou = tf.reduce_mean(iou * class_weights)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b71a9af-2025-4b73-989f-6314ba740989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #build model\n",
    "# import segmentation_models as sm\n",
    "# from keras.layers import *\n",
    "# from keras import layers\n",
    "# from keras.models import Model\n",
    "\n",
    "# def SEModule(input, ratio, out_dim):\n",
    "#     # bs, c, h, w\n",
    "#     x = GlobalAveragePooling2D()(input)\n",
    "#     excitation = Dense(units=out_dim // ratio)(x)\n",
    "#     excitation = Activation('relu')(excitation)\n",
    "#     excitation = Dense(units=out_dim)(excitation)\n",
    "#     excitation = Activation('sigmoid')(excitation)\n",
    "#     excitation = Reshape((1, 1, out_dim))(excitation)\n",
    "#     scale = multiply([input, excitation])\n",
    "#     return scale\n",
    "\n",
    "\n",
    "# def SEUnet(nClasses, input_height=224, input_width=224):\n",
    "   \n",
    "#     inputs = Input(shape=(input_height, input_width, 3))\n",
    "#     conv1 = Conv2D(16,\n",
    "#                    3,\n",
    "#                   activation='relu',\n",
    "#                   padding='same',\n",
    "#                   kernel_initializer='he_normal')(conv1)\n",
    "#     ## quantizing 1st layer\n",
    "#     quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "#     conv1 = quantize_annotate_layer(conv1)\n",
    "#     conv1 =  Normalization(axis=-1)(conv1)\n",
    "#     inputs = Input(shape=(input_height, input_width, 3))\n",
    "#     conv1 = Conv2D(16,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(inputs)\n",
    "#     conv1 = Normalization(axis=-1)(conv1)\n",
    "#     # se\n",
    "#     conv1 = SEModule(conv1, 4, 16)\n",
    "\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = Conv2D(32,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(pool1)\n",
    "#     conv2 = Normalization(axis=-1)(conv2)\n",
    "\n",
    "#     conv2 = Conv2D(32,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv2)\n",
    "#     conv2 = Normalization(axis=-1)(conv2)\n",
    "\n",
    "#     # se\n",
    "#     conv2 = SEModule(conv2, 8, 32)\n",
    "\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = Conv2D(64,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(pool2)\n",
    "#     conv3 = Normalization(axis=-1)(conv3)\n",
    "\n",
    "#     conv3 = Conv2D(64,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv3)\n",
    "#     conv3 = Normalization(axis=-1)(conv3)\n",
    "\n",
    "#     # se\n",
    "#     conv3 = SEModule(conv3, 8, 64)\n",
    "\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     conv4 = Conv2D(128,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(pool3)\n",
    "#     conv4 = Normalization(axis=-1)(conv4)\n",
    "\n",
    "#     conv4 = Conv2D(128,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv4)\n",
    "#     conv4 = Normalization(axis=-1)(conv4)\n",
    "\n",
    "#     # se\n",
    "#     conv4 = SEModule(conv4, 16, 128)\n",
    "\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "#     conv5 = Conv2D(256,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(pool4)\n",
    "#     conv5 = Normalization(axis=-1)(conv5)\n",
    "#     conv5 = Conv2D(256,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv5)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "#     # se\n",
    "#     conv5 = SEModule(conv5, 16, 256)\n",
    "\n",
    "#     up6 = Conv2D(128,\n",
    "#                  2,\n",
    "#                  activation='relu',\n",
    "#                  padding='same',\n",
    "#                  kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "#                                                                     2))(conv5))\n",
    "#     up6 = Normalization(axis=-1)(up6)\n",
    "\n",
    "#     merge6 = concatenate([conv4, up6], axis=3)\n",
    "#     conv6 = Conv2D(128,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(merge6)\n",
    "#     conv6 = Normalization(axis=-1)(conv6)\n",
    "\n",
    "#     conv6 = Conv2D(128,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv6)\n",
    "#     conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "#     # se\n",
    "#     conv6 = SEModule(conv6, 16, 128)\n",
    "\n",
    "#     up7 = Conv2D(64,\n",
    "#                  2,\n",
    "#                  activation='relu',\n",
    "#                  padding='same',\n",
    "#                  kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "#                                                                     2))(conv6))\n",
    "#     up7 = Normalization(axis=-1)(up7)\n",
    "\n",
    "#     merge7 = concatenate([conv3, up7], axis=3)\n",
    "#     conv7 = Conv2D(64,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(merge7)\n",
    "#     conv7 = Normalization(axis=-1)(conv7)\n",
    "\n",
    "#     conv7 = Conv2D(64,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv7)\n",
    "#     conv7 = Normalization(axis=-1)(conv7)\n",
    "\n",
    "#     # se\n",
    "#     conv7 = SEModule(conv7, 8, 64)\n",
    "\n",
    "#     up8 = Conv2D(32,\n",
    "#                  2,\n",
    "#                  activation='relu',\n",
    "#                  padding='same',\n",
    "#                  kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "#                                                                     2))(conv7))\n",
    "#     up8 = Normalization(axis=-1)(up8)\n",
    "\n",
    "#     merge8 = concatenate([conv2, up8], axis=3)\n",
    "#     conv8 = Conv2D(32,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(merge8)\n",
    "#     conv8 = Normalization(axis=-1)(conv8)\n",
    "\n",
    "#     conv8 = Conv2D(32,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv8)\n",
    "#     conv8 =Normalization(axis=-1)(conv8)\n",
    "\n",
    "#     # se\n",
    "#     conv8 = SEModule(conv8, 4, 32)\n",
    "\n",
    "#     up9 = Conv2D(16,\n",
    "#                  2,\n",
    "#                  activation='relu',\n",
    "#                  padding='same',\n",
    "#                  kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "#                                                                     2))(conv8))\n",
    "#     up9 = Normalization(axis=-1)(up9)\n",
    "\n",
    "#     merge9 = concatenate([conv1, up9], axis=3)\n",
    "#     conv9 = Conv2D(16,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(merge9)\n",
    "#     conv9 = Normalization(axis=-1)(conv9)\n",
    "\n",
    "#     conv9 = Conv2D(16,\n",
    "#                    3,\n",
    "#                    activation='relu',\n",
    "#                    padding='same',\n",
    "#                    kernel_initializer='he_normal')(conv9)\n",
    "#     conv9 = Normalization(axis=-1)(conv9)\n",
    "\n",
    "#     # se\n",
    "#     conv9 = SEModule(conv9, 2, 16)\n",
    "\n",
    "#     conv10 = Conv2D(nClasses, (3, 3), padding='same')(conv9)\n",
    "#     conv10 = Normalization(axis=-1)(conv10)\n",
    "\n",
    "#     outputHeight = Model(inputs, conv10).output_shape[1]\n",
    "#     outputWidth = Model(inputs, conv10).output_shape[2]\n",
    "\n",
    "#     out = (Reshape((outputHeight * outputWidth, nClasses)))(conv10)\n",
    "#     out = Activation('softmax')(out)\n",
    "\n",
    "#     model = Model(inputs,out)\n",
    "#     model.outputHeight = outputHeight\n",
    "#     model.outputWidth = outputWidth\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model1 = SEUnet(nClasses=5)\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37fd563b-480d-4ed4-90f0-4d65d3cc792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import segmentation_models as sm\n",
    "# from keras.layers import *\n",
    "# from keras import layers\n",
    "# from keras.models import Model\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# def SEModule(input, ratio, out_dim):\n",
    "#     x = GlobalAveragePooling2D()(input)\n",
    "#     excitation = Dense(units=out_dim // ratio)(x)\n",
    "#     excitation = Activation('relu')(excitation)\n",
    "#     excitation = Dense(units=out_dim)(excitation)\n",
    "#     excitation = Activation('sigmoid')(excitation)\n",
    "#     excitation = Reshape((1, 1, out_dim))(excitation)\n",
    "#     scale = multiply([input, excitation])\n",
    "#     return scale\n",
    "\n",
    "# def SEUnet(nClasses, input_height=224, input_width=224):\n",
    "#     inputs = Input(shape=(input_height, input_width, 3))\n",
    "    \n",
    "#     quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "#     conv1 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(inputs)\n",
    "    \n",
    "#     conv1 = Normalization(axis=-1)(conv1)\n",
    "    \n",
    "#     # SE\n",
    "#     conv1 = SEModule(conv1, 4, 16)\n",
    "\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool1)\n",
    "#     conv2 = Normalization(axis=-1)(conv2)\n",
    "#     conv2 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv2)\n",
    "#     conv2 = Normalization(axis=-1)(conv2)\n",
    "    \n",
    "#     # SE\n",
    "#     conv2 = SEModule(conv2, 8, 32)\n",
    "\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool2)\n",
    "#     conv3 = Normalization(axis=-1)(conv3)\n",
    "#     conv3 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv3)\n",
    "#     conv3 = Normalization(axis=-1)(conv3)\n",
    "    \n",
    "#     # SE\n",
    "#     conv3 = SEModule(conv3, 8, 64)\n",
    "\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     conv4 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool3)\n",
    "#     conv4 = Normalization(axis=-1)(conv4)\n",
    "#     conv4 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv4)\n",
    "#     conv4 = Normalization(axis=-1)(conv4)\n",
    "    \n",
    "#     # SE\n",
    "#     conv4 = SEModule(conv4, 16, 128)\n",
    "\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "#     conv5 = quantize_annotate_layer(\n",
    "#         Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool4)\n",
    "#     conv5 = Normalization(axis=-1)(conv5)\n",
    "#     conv5 = quantize_annotate_layer(\n",
    "#         Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv5)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "#     # SE\n",
    "#     conv5 = SEModule(conv5, 16, 256)\n",
    "\n",
    "#     up6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv5))\n",
    "#     up6 = Normalization(axis=-1)(up6)\n",
    "#     merge6 = concatenate([conv4, up6], axis=3)\n",
    "#     conv6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge6)\n",
    "#     conv6 = Normalization(axis=-1)(conv6)\n",
    "#     conv6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv6)\n",
    "#     conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "#     # SE\n",
    "#     conv6 = SEModule(conv6, 16, 128)\n",
    "\n",
    "#     up7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv6))\n",
    "#     up7 = Normalization(axis=-1)(up7)\n",
    "#     merge7 = concatenate([conv3, up7], axis=3)\n",
    "#     conv7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge7)\n",
    "#     conv7 = Normalization(axis=-1)(conv7)\n",
    "#     conv7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv7)\n",
    "#     conv7 = Normalization(axis=-1)(conv7)\n",
    "    \n",
    "#     # SE\n",
    "#     conv7 = SEModule(conv7, 8, 64)\n",
    "\n",
    "#     up8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv7))\n",
    "#     up8 = Normalization(axis=-1)(up8)\n",
    "#     merge8 = concatenate([conv2, up8], axis=3)\n",
    "#     conv8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge8)\n",
    "#     conv8 = Normalization(axis=-1)(conv8)\n",
    "#     conv8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv8)\n",
    "#     conv8 = Normalization(axis=-1)(conv8)\n",
    "    \n",
    "#     # SE\n",
    "#     conv8 = SEModule(conv8, 4, 32)\n",
    "\n",
    "#     up9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv8))\n",
    "#     up9 = Normalization(axis=-1)(up9)\n",
    "#     merge9 = concatenate([conv1, up9], axis=3)\n",
    "#     conv9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge9)\n",
    "#     conv9 = Normalization(axis=-1)(conv9)\n",
    "#     conv9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv9)\n",
    "#     conv9 = Normalization(axis=-1)(conv9)\n",
    "    \n",
    "#     # SE\n",
    "#     conv9 = SEModule(conv9, 2, 16)\n",
    "\n",
    "#     conv10 = quantize_annotate_layer(\n",
    "#         Conv2D(nClasses, (3, 3), padding='same')\n",
    "#     )(conv9)\n",
    "#     conv10 = Normalization(axis=-1)(conv10)\n",
    "\n",
    "#     outputHeight = Model(inputs, conv10).output_shape[1]\n",
    "#     outputWidth = Model(inputs, conv10).output_shape[2]\n",
    "\n",
    "#     out = Reshape((outputHeight * outputWidth, nClasses))(conv10)\n",
    "#     out = Activation('softmax')(out)\n",
    "\n",
    "#     model = Model(inputs, out)\n",
    "#     model.outputHeight = outputHeight\n",
    "#     model.outputWidth = outputWidth\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model1 = SEUnet(nClasses=5)\n",
    "# model1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9dff5e-dd0a-429e-ac4b-a5843153c40c",
   "metadata": {},
   "source": [
    "## QAT without quantconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e27f6b7f-3eb3-4f99-87e9-9ca2c0a14183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import segmentation_models as sm\n",
    "# from keras.layers import *\n",
    "# from keras import layers\n",
    "# from keras.models import Model\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# def SEModule(input, ratio, out_dim):\n",
    "#     x = GlobalAveragePooling2D()(input)\n",
    "#     excitation = Dense(units=out_dim // ratio)(x)\n",
    "#     excitation = Activation('relu')(excitation)\n",
    "#     excitation = Dense(units=out_dim)(excitation)\n",
    "#     excitation = Activation('sigmoid')(excitation)\n",
    "#     excitation = Reshape((1, 1, out_dim))(excitation)\n",
    "#     scale = multiply([input, excitation])\n",
    "#     return scale\n",
    "\n",
    "# def SEUnet(nClasses, input_height=224, input_width=224):\n",
    "#     inputs = Input(shape=(input_height, input_width, 3))\n",
    "    \n",
    "#     quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "#     conv1 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(inputs)\n",
    "    \n",
    "#     conv1 = BatchNormalization()(conv1)\n",
    "#     conv1 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(inputs)\n",
    "#     conv1 = BatchNormalization()(conv1)\n",
    "#     # SE\n",
    "#     conv1 = SEModule(conv1, 4, 16)\n",
    "\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool1)\n",
    "#     conv2 = BatchNormalization()(conv2)\n",
    "#     conv2 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv2)\n",
    "#     conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "#     # SE\n",
    "#     conv2 = SEModule(conv2, 8, 32)\n",
    "\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool2)\n",
    "#     conv3 = BatchNormalization()(conv3)\n",
    "#     conv3 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv3)\n",
    "#     conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "#     # SE\n",
    "#     conv3 = SEModule(conv3, 8, 64)\n",
    "\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     conv4 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool3)\n",
    "#     conv4 = BatchNormalization()(conv4)\n",
    "#     conv4 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv4)\n",
    "#     conv4 = BatchNormalization()(conv4)\n",
    "    \n",
    "#     # SE\n",
    "#     conv4 = SEModule(conv4, 16, 128)\n",
    "\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "#     conv5 = quantize_annotate_layer(\n",
    "#         Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool4)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "#     conv5 = quantize_annotate_layer(\n",
    "#         Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv5)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "#     # SE\n",
    "#     conv5 = SEModule(conv5, 16, 256)\n",
    "\n",
    "#     up6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv5))\n",
    "#     up6 = BatchNormalization()(up6)\n",
    "#     merge6 = concatenate([conv4, up6], axis=3)\n",
    "#     conv6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge6)\n",
    "#     conv6 = BatchNormalization()(conv6)\n",
    "#     conv6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv6)\n",
    "#     conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "#     # SE\n",
    "#     conv6 = SEModule(conv6, 16, 128)\n",
    "\n",
    "#     up7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv6))\n",
    "#     up7 = BatchNormalization()(up7)\n",
    "#     merge7 = concatenate([conv3, up7], axis=3)\n",
    "#     conv7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge7)\n",
    "#     conv7 = BatchNormalization()(conv7)\n",
    "#     conv7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv7)\n",
    "#     conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "#     # SE\n",
    "#     conv7 = SEModule(conv7, 8, 64)\n",
    "\n",
    "#     up8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv7))\n",
    "#     up8 = BatchNormalization()(up8)\n",
    "#     merge8 = concatenate([conv2, up8], axis=3)\n",
    "#     conv8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge8)\n",
    "#     conv8 = BatchNormalization()(conv8)\n",
    "#     conv8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv8)\n",
    "#     conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "#     # SE\n",
    "#     conv8 = SEModule(conv8, 4, 32)\n",
    "\n",
    "#     up9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv8))\n",
    "#     up9 = BatchNormalization()(up9)\n",
    "#     merge9 = concatenate([conv1, up9], axis=3)\n",
    "#     conv9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge9)\n",
    "#     conv9 = BatchNormalization()(conv9)\n",
    "#     conv9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv9)\n",
    "#     conv9 = BatchNormalization()(conv9)\n",
    "    \n",
    "#     # SE\n",
    "#     conv9 = SEModule(conv9, 2, 16)\n",
    "\n",
    "#     conv10 = quantize_annotate_layer(\n",
    "#         Conv2D(nClasses, (3, 3), padding='same')\n",
    "#     )(conv9)\n",
    "#     conv10 = BatchNormalization()(conv10)\n",
    "\n",
    "#     outputHeight = Model(inputs, conv10).output_shape[1]\n",
    "#     outputWidth = Model(inputs, conv10).output_shape[2]\n",
    "\n",
    "#     out = Reshape((outputHeight * outputWidth, nClasses))(conv10)\n",
    "#     out = Activation('softmax')(out)\n",
    "\n",
    "#     model = Model(inputs, out)\n",
    "#     model.outputHeight = outputHeight\n",
    "#     model.outputWidth = outputWidth\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model1 = SEUnet(nClasses=5)\n",
    "# model1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba1a18-f16a-40fa-8dea-6a282e2ab9c4",
   "metadata": {},
   "source": [
    "## QAT with Quant config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84a7a8d5-51a1-40af-9a2a-fd0a9d7004c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ConvQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "#     def get_weights_and_quantizers(self, layer):\n",
    "#         return [(layer.kernel, tfmot.quantization.keras.quantizers.LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "#     def get_activations_and_quantizers(self, layer):\n",
    "#         return [(layer.activation, tfmot.quantization.keras.quantizers.MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False))]\n",
    "\n",
    "#     def set_quantize_weights(self, layer, quantize_weights):\n",
    "#         layer.kernel = quantize_weights[0]\n",
    "\n",
    "#     def set_quantize_activations(self, layer, quantize_activations):\n",
    "#         pass  # No need to explicitly set quantized activations\n",
    "\n",
    "#     def get_output_quantizers(self, layer):\n",
    "#         return [tfmot.quantization.keras.quantizers.MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False)]\n",
    "\n",
    "#     def get_config(self):\n",
    "#         return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1b82133-11f8-4312-84f3-bad3aba25d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantizers import MovingAverageQuantizer, LastValueQuantizer\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantize_config import QuantizeConfig\n",
    "from keras.layers import Layer\n",
    "\n",
    "# Custom QuantizeConfig for Conv2D layers\n",
    "class ConvQuantizeConfig(QuantizeConfig):\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return [(layer.kernel, LastValueQuantizer(num_bits=4, per_axis=False, symmetric=False, narrow_range=False))]\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        return [(layer.activation, MovingAverageQuantizer(num_bits=4, per_axis=False, symmetric=False, narrow_range=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        layer.activation = quantize_activations[0]\n",
    "\n",
    "    def get_output_quantizers(self, layer):\n",
    "        # Does not quantize output, since we return an empty list.\n",
    "        return []\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38409a54-9f28-4672-88ff-929b6139c1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ConvQuantizeConfig"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.register_keras_serializable(package='QuantizeConfig')(ConvQuantizeConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a38306a1-a7c0-4ca4-9233-d88d774e9850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " quantize_annotate (QuantizeAnn  (None, 224, 224, 16  448        ['input_1[0][0]']                \n",
      " otate)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 224, 224, 16  64         ['quantize_annotate[0][0]']      \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_1 (QuantizeA  (None, 224, 224, 16  2320       ['batch_normalization[0][0]']    \n",
      " nnotate)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 224, 224, 16  64         ['quantize_annotate_1[0][0]']    \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 16)          0           ['batch_normalization_1[0][0]']  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            68          ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 4)            0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           80          ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 16)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 224, 224, 16  0           ['batch_normalization_1[0][0]',  \n",
      "                                )                                 'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['multiply[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_2 (QuantizeA  (None, 112, 112, 32  4640       ['max_pooling2d[0][0]']          \n",
      " nnotate)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 112, 112, 32  128        ['quantize_annotate_2[0][0]']    \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_3 (QuantizeA  (None, 112, 112, 32  9248       ['batch_normalization_2[0][0]']  \n",
      " nnotate)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 112, 32  128        ['quantize_annotate_3[0][0]']    \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 32)          0           ['batch_normalization_3[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4)            132         ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 4)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           160         ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 32)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 112, 112, 32  0           ['batch_normalization_3[0][0]',  \n",
      "                                )                                 'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_4 (QuantizeA  (None, 56, 56, 64)  18496       ['max_pooling2d_1[0][0]']        \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['quantize_annotate_4[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " quantize_annotate_5 (QuantizeA  (None, 56, 56, 64)  36928       ['batch_normalization_4[0][0]']  \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['quantize_annotate_5[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 64)          0           ['batch_normalization_5[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 8)            520         ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 8)            0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           576         ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1, 64)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_6 (QuantizeA  (None, 28, 28, 128)  73856      ['max_pooling2d_2[0][0]']        \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 128)  512        ['quantize_annotate_6[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " quantize_annotate_7 (QuantizeA  (None, 28, 28, 128)  147584     ['batch_normalization_6[0][0]']  \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 28, 28, 128)  512        ['quantize_annotate_7[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 128)         0           ['batch_normalization_7[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 8)            1032        ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 8)            0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          1152        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 128)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1, 128)    0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 28, 28, 128)  0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0          ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_8 (QuantizeA  (None, 14, 14, 256)  295168     ['max_pooling2d_3[0][0]']        \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 14, 14, 256)  1024       ['quantize_annotate_8[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " quantize_annotate_9 (QuantizeA  (None, 14, 14, 256)  590080     ['batch_normalization_8[0][0]']  \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 14, 14, 256)  1024       ['quantize_annotate_9[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 256)         0           ['batch_normalization_9[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16)           4112        ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          4352        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 256)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 256)    0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 14, 14, 256)  0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 28, 28, 256)  0           ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_10 (Quantize  (None, 28, 28, 128)  131200     ['up_sampling2d[0][0]']          \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 28, 28, 128)  512        ['quantize_annotate_10[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 28, 256)  0           ['multiply_3[0][0]',             \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_11 (Quantize  (None, 28, 28, 128)  295040     ['concatenate[0][0]']            \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 28, 28, 128)  512        ['quantize_annotate_11[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " quantize_annotate_12 (Quantize  (None, 28, 28, 128)  147584     ['batch_normalization_11[0][0]'] \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 28, 28, 128)  512        ['quantize_annotate_12[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['batch_normalization_12[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 8)            1032        ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8)            0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 128)          1152        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 128)          0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1, 128)    0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 28, 28, 128)  0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 128)  0          ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_13 (Quantize  (None, 56, 56, 64)  32832       ['up_sampling2d_1[0][0]']        \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 56, 56, 64)  256         ['quantize_annotate_13[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 56, 56, 128)  0           ['multiply_2[0][0]',             \n",
      "                                                                  'batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_14 (Quantize  (None, 56, 56, 64)  73792       ['concatenate_1[0][0]']          \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 56, 56, 64)  256         ['quantize_annotate_14[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " quantize_annotate_15 (Quantize  (None, 56, 56, 64)  36928       ['batch_normalization_14[0][0]'] \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 56, 56, 64)  256         ['quantize_annotate_15[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 64)          0           ['batch_normalization_15[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 8)            520         ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 8)            0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           576         ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 64)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1, 64)     0           ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 56, 56, 64)   0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 64  0          ['multiply_6[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_16 (Quantize  (None, 112, 112, 32  8224       ['up_sampling2d_2[0][0]']        \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 112, 112, 32  128        ['quantize_annotate_16[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 112, 112, 64  0           ['multiply_1[0][0]',             \n",
      "                                )                                 'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_17 (Quantize  (None, 112, 112, 32  18464      ['concatenate_2[0][0]']          \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 112, 112, 32  128        ['quantize_annotate_17[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_18 (Quantize  (None, 112, 112, 32  9248       ['batch_normalization_17[0][0]'] \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 112, 112, 32  128        ['quantize_annotate_18[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 32)          0           ['batch_normalization_18[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 8)            264         ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8)            0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           288         ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 1, 32)     0           ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 112, 112, 32  0           ['batch_normalization_18[0][0]', \n",
      "                                )                                 'reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['multiply_7[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_19 (Quantize  (None, 224, 224, 16  2064       ['up_sampling2d_3[0][0]']        \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 224, 224, 16  64         ['quantize_annotate_19[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 32  0           ['multiply[0][0]',               \n",
      "                                )                                 'batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_20 (Quantize  (None, 224, 224, 16  4624       ['concatenate_3[0][0]']          \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 224, 224, 16  64         ['quantize_annotate_20[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_21 (Quantize  (None, 224, 224, 16  2320       ['batch_normalization_20[0][0]'] \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 224, 224, 16  64         ['quantize_annotate_21[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 16)          0           ['batch_normalization_21[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 8)            136         ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8)            0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 16)           144         ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 1, 16)     0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 224, 224, 16  0           ['batch_normalization_21[0][0]', \n",
      "                                )                                 'reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " quantize_annotate_22 (Quantize  (None, 224, 224, 5)  725        ['multiply_8[0][0]']             \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 224, 224, 5)  20         ['quantize_annotate_22[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " reshape_9 (Reshape)            (None, 50176, 5)     0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 50176, 5)     0           ['reshape_9[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,964,977\n",
      "Trainable params: 1,961,543\n",
      "Non-trainable params: 3,434\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "import segmentation_models as sm\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def SEModule(input, ratio, out_dim):\n",
    "    x = GlobalAveragePooling2D()(input)\n",
    "    excitation = Dense(units=out_dim // ratio)(x)\n",
    "    excitation = Activation('relu')(excitation)\n",
    "    excitation = Dense(units=out_dim)(excitation)\n",
    "    excitation = Activation('sigmoid')(excitation)\n",
    "    excitation = Reshape((1, 1, out_dim))(excitation)\n",
    "    scale = multiply([input, excitation])\n",
    "    return scale\n",
    "\n",
    "def SEUnet(nClasses, input_height=224, input_width=224):\n",
    "    inputs = Input(shape=(input_height, input_width, 3))\n",
    "    quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "    \n",
    "    conv1 = quantize_annotate_layer(\n",
    "        Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(inputs)\n",
    "    \n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = quantize_annotate_layer(\n",
    "        Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    # SE\n",
    "    conv1 = SEModule(conv1, 4, 16)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = quantize_annotate_layer(\n",
    "        Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = quantize_annotate_layer(\n",
    "        Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "    # SE\n",
    "    conv2 = SEModule(conv2, 8, 32)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = quantize_annotate_layer(\n",
    "        Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = quantize_annotate_layer(\n",
    "        Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "    # SE\n",
    "    conv3 = SEModule(conv3, 8, 64)\n",
    "\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = quantize_annotate_layer(\n",
    "        Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = quantize_annotate_layer(\n",
    "        Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    \n",
    "    # SE\n",
    "    conv4 = SEModule(conv4, 16, 128)\n",
    "\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    conv5 = quantize_annotate_layer(\n",
    "        Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = quantize_annotate_layer(\n",
    "        Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "    # SE\n",
    "    conv5 = SEModule(conv5, 16, 256)\n",
    "\n",
    "    up6 = quantize_annotate_layer(\n",
    "        Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(UpSampling2D(size=(2, 2))(conv5))\n",
    "    up6 = BatchNormalization()(up6)\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = quantize_annotate_layer(\n",
    "        Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = quantize_annotate_layer(\n",
    "        Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "    # SE\n",
    "    conv6 = SEModule(conv6, 16, 128)\n",
    "\n",
    "    up7 = quantize_annotate_layer(\n",
    "        Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(UpSampling2D(size=(2, 2))(conv6))\n",
    "    up7 = BatchNormalization()(up7)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = quantize_annotate_layer(\n",
    "        Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = quantize_annotate_layer(\n",
    "        Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "    # SE\n",
    "    conv7 = SEModule(conv7, 8, 64)\n",
    "\n",
    "    up8 = quantize_annotate_layer(\n",
    "        Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(UpSampling2D(size=(2, 2))(conv7))\n",
    "    up8 = BatchNormalization()(up8)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = quantize_annotate_layer(\n",
    "        Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = quantize_annotate_layer(\n",
    "        Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "    # SE\n",
    "    conv8 = SEModule(conv8, 4, 32)\n",
    "\n",
    "    up9 = quantize_annotate_layer(\n",
    "        Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(UpSampling2D(size=(2, 2))(conv8))\n",
    "    up9 = BatchNormalization()(up9)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = quantize_annotate_layer(\n",
    "        Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = quantize_annotate_layer(\n",
    "        Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    \n",
    "    # SE\n",
    "    conv9 = SEModule(conv9, 2, 16)\n",
    "\n",
    "    conv10 = quantize_annotate_layer(\n",
    "        Conv2D(nClasses, (3, 3), padding='same'),\n",
    "        quantize_config=ConvQuantizeConfig()\n",
    "    )(conv9)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "\n",
    "    outputHeight = Model(inputs, conv10).output_shape[1]\n",
    "    outputWidth = Model(inputs, conv10).output_shape[2]\n",
    "\n",
    "    out = Reshape((outputHeight * outputWidth, nClasses))(conv10)\n",
    "    out = Activation('softmax')(out)\n",
    "\n",
    "    model = Model(inputs, out)\n",
    "    model.outputHeight = outputHeight\n",
    "    model.outputWidth = outputWidth\n",
    "\n",
    "    return model\n",
    "model1 = SEUnet(nClasses=5)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72732e6c-8796-43b3-bcb7-400ca67e7144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " quantize_annotate (QuantizeAnn  (None, 224, 224, 16  448        ['input_1[0][0]']                \n",
      " otate)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 224, 224, 16  64         ['quantize_annotate[0][0]']      \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_1 (QuantizeA  (None, 224, 224, 16  2320       ['batch_normalization[0][0]']    \n",
      " nnotate)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 224, 224, 16  64         ['quantize_annotate_1[0][0]']    \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 16)          0           ['batch_normalization_1[0][0]']  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4)            68          ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 4)            0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           80          ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 16)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 224, 224, 16  0           ['batch_normalization_1[0][0]',  \n",
      "                                )                                 'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 112, 112, 16  0           ['multiply[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_2 (QuantizeA  (None, 112, 112, 32  4640       ['max_pooling2d[0][0]']          \n",
      " nnotate)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 112, 112, 32  128        ['quantize_annotate_2[0][0]']    \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_3 (QuantizeA  (None, 112, 112, 32  9248       ['batch_normalization_2[0][0]']  \n",
      " nnotate)                       )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 112, 112, 32  128        ['quantize_annotate_3[0][0]']    \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 32)          0           ['batch_normalization_3[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 4)            132         ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 4)            0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           160         ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 32)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 112, 112, 32  0           ['batch_normalization_3[0][0]',  \n",
      "                                )                                 'reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_4 (QuantizeA  (None, 56, 56, 64)  18496       ['max_pooling2d_1[0][0]']        \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 56, 56, 64)  256         ['quantize_annotate_4[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " quantize_annotate_5 (QuantizeA  (None, 56, 56, 64)  36928       ['batch_normalization_4[0][0]']  \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 56, 56, 64)  256         ['quantize_annotate_5[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 64)          0           ['batch_normalization_5[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 8)            520         ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 8)            0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           576         ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1, 1, 64)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 56, 56, 64)   0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 64)  0           ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_6 (QuantizeA  (None, 28, 28, 128)  73856      ['max_pooling2d_2[0][0]']        \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 28, 128)  512        ['quantize_annotate_6[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " quantize_annotate_7 (QuantizeA  (None, 28, 28, 128)  147584     ['batch_normalization_6[0][0]']  \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 28, 28, 128)  512        ['quantize_annotate_7[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 128)         0           ['batch_normalization_7[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 8)            1032        ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 8)            0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          1152        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 128)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 1, 1, 128)    0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 28, 28, 128)  0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'reshape_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 128)  0          ['multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_8 (QuantizeA  (None, 14, 14, 256)  295168     ['max_pooling2d_3[0][0]']        \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 14, 14, 256)  1024       ['quantize_annotate_8[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " quantize_annotate_9 (QuantizeA  (None, 14, 14, 256)  590080     ['batch_normalization_8[0][0]']  \n",
      " nnotate)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 14, 14, 256)  1024       ['quantize_annotate_9[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_4 (Gl  (None, 256)         0           ['batch_normalization_9[0][0]']  \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16)           4112        ['global_average_pooling2d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          4352        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 256)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 1, 1, 256)    0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 14, 14, 256)  0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'reshape_4[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 28, 28, 256)  0           ['multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_10 (Quantize  (None, 28, 28, 128)  131200     ['up_sampling2d[0][0]']          \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 28, 28, 128)  512        ['quantize_annotate_10[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 28, 256)  0           ['multiply_3[0][0]',             \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_11 (Quantize  (None, 28, 28, 128)  295040     ['concatenate[0][0]']            \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 28, 28, 128)  512        ['quantize_annotate_11[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " quantize_annotate_12 (Quantize  (None, 28, 28, 128)  147584     ['batch_normalization_11[0][0]'] \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 28, 28, 128)  512        ['quantize_annotate_12[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['batch_normalization_12[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 8)            1032        ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8)            0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 128)          1152        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 128)          0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 1, 1, 128)    0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 28, 28, 128)  0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'reshape_5[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 56, 56, 128)  0          ['multiply_5[0][0]']             \n",
      "                                                                                                  \n",
      " quantize_annotate_13 (Quantize  (None, 56, 56, 64)  32832       ['up_sampling2d_1[0][0]']        \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 56, 56, 64)  256         ['quantize_annotate_13[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 56, 56, 128)  0           ['multiply_2[0][0]',             \n",
      "                                                                  'batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_14 (Quantize  (None, 56, 56, 64)  73792       ['concatenate_1[0][0]']          \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 56, 56, 64)  256         ['quantize_annotate_14[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " quantize_annotate_15 (Quantize  (None, 56, 56, 64)  36928       ['batch_normalization_14[0][0]'] \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 56, 56, 64)  256         ['quantize_annotate_15[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " global_average_pooling2d_6 (Gl  (None, 64)          0           ['batch_normalization_15[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 8)            520         ['global_average_pooling2d_6[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 8)            0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 64)           576         ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 64)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 1, 1, 64)     0           ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 56, 56, 64)   0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 112, 112, 64  0          ['multiply_6[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_16 (Quantize  (None, 112, 112, 32  8224       ['up_sampling2d_2[0][0]']        \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 112, 112, 32  128        ['quantize_annotate_16[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 112, 112, 64  0           ['multiply_1[0][0]',             \n",
      "                                )                                 'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_17 (Quantize  (None, 112, 112, 32  18464      ['concatenate_2[0][0]']          \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 112, 112, 32  128        ['quantize_annotate_17[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_18 (Quantize  (None, 112, 112, 32  9248       ['batch_normalization_17[0][0]'] \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 112, 112, 32  128        ['quantize_annotate_18[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7 (Gl  (None, 32)          0           ['batch_normalization_18[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 8)            264         ['global_average_pooling2d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8)            0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           288         ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 1, 1, 32)     0           ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 112, 112, 32  0           ['batch_normalization_18[0][0]', \n",
      "                                )                                 'reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 224, 224, 32  0          ['multiply_7[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_19 (Quantize  (None, 224, 224, 16  2064       ['up_sampling2d_3[0][0]']        \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 224, 224, 16  64         ['quantize_annotate_19[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 224, 224, 32  0           ['multiply[0][0]',               \n",
      "                                )                                 'batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " quantize_annotate_20 (Quantize  (None, 224, 224, 16  4624       ['concatenate_3[0][0]']          \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 224, 224, 16  64         ['quantize_annotate_20[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " quantize_annotate_21 (Quantize  (None, 224, 224, 16  2320       ['batch_normalization_20[0][0]'] \n",
      " Annotate)                      )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 224, 224, 16  64         ['quantize_annotate_21[0][0]']   \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 16)          0           ['batch_normalization_21[0][0]'] \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 8)            136         ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8)            0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 16)           144         ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1, 1, 16)     0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_8 (Multiply)          (None, 224, 224, 16  0           ['batch_normalization_21[0][0]', \n",
      "                                )                                 'reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      " quantize_annotate_22 (Quantize  (None, 224, 224, 5)  725        ['multiply_8[0][0]']             \n",
      " Annotate)                                                                                        \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 224, 224, 5)  20         ['quantize_annotate_22[0][0]']   \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sprout (Conv2D)                (None, 224, 224, 2)  12          ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " peeled (Conv2D)                (None, 224, 224, 2)  12          ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " rotten (Conv2D)                (None, 224, 224, 2)  12          ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " double (Conv2D)                (None, 224, 224, 2)  12          ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " background (Conv2D)            (None, 224, 224, 2)  12          ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,965,037\n",
      "Trainable params: 1,961,603\n",
      "Non-trainable params: 3,434\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = model1.get_layer(index=-3).output\n",
    "\n",
    "# folder=[\"Sprout\",\"Black_smut\",\"Rotten\",\"Background\"]\n",
    "out0 = Conv2D(2, (1, 1), activation='softmax',name='sprout')(x)\n",
    "out1 = Conv2D(2, (1, 1), activation='softmax',name='peeled')(x)\n",
    "out2 = Conv2D(2, (1, 1), activation='softmax',name='rotten')(x)\n",
    "out3 = Conv2D(2, (1, 1), activation='softmax',name='double')(x)\n",
    "out4 = Conv2D(2, (1, 1), activation='softmax',name='background')(x)\n",
    "model_new = Model(inputs = model1.input,outputs = [out0,out1,out2,out3,out4])\n",
    "# Register custom objects and apply quantization\n",
    "# with tfmot.quantization.keras.quantize_scope({'ConvQuantizeConfig': ConvQuantizeConfig}):\n",
    "#     quantized_model = tfmot.quantization.keras.quantize_apply(model_new)\n",
    "\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad1be7-974c-421d-ad20-af3d420ead4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d08744a-66b0-454e-886c-cc190afb3027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdfe5205-db00-4c59-847d-9f3fd75bd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = tfmot.quantization.keras.quantize_apply(model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f0512fe-d808-4c78-8310-2f172cbc7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models.metrics import  f1_score,precision,recall\n",
    "from segmentation_models.metrics import  f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f418240-7a0d-4d68-b033-c581e441b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfb1506b-bc9a-4bbe-a4cd-72b0180e42c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agrograde/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_name = 'onin_28th_june_spplrobg'\n",
    "date = '28thjune2024'\n",
    "learning_rate = 0.001\n",
    "# num_epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the optimizer\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Define losses, metrics, and loss weights\n",
    "losses = {\"sprout\": sm.losses.bce_jaccard_loss, \"peeled\": sm.losses.bce_jaccard_loss, \"rotten\": sm.losses.bce_jaccard_loss,\"double\": sm.losses.bce_jaccard_loss,\"background\": sm.losses.bce_jaccard_loss}\n",
    "metrics = {\"sprout\": [iou_score, f1_score,precision,recall], \"peeled\": [iou_score, f1_score,precision,recall], \"rotten\": [iou_score, f1_score,precision,recall],\"double\": [iou_score, f1_score,precision,recall], \"background\": [iou_score, f1_score,precision,recall]}\n",
    "loss_weights = {\"sprout\": 1.0, \"peeled\": 1.0, \"rotten\": 1.0, \"double\": 1.0, \"background\": 2.0}\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "LR_Reduce_callback = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto')\n",
    "#model_ckpt1 = ModelCheckpoint(model_name+'_'+date+'.h5', monitor='loss', save_weights_only=False,save_best_only=True, period=1)\n",
    "model_ckpt2 = ModelCheckpoint(model_name+'_'+date+'_weights.h5', monitor='loss', save_weights_only=True,save_best_only=True, period=1)\n",
    "# reduce_rl_plateau = CustomReduceLRoP(patience=4, \n",
    "#                               verbose=1, \n",
    "#                               optim_lr=opt.learning_rate, \n",
    "#                               mode='auto',\n",
    "#                               factor=0.1)\n",
    "# Compile the model using the initialized optimizer\n",
    "quantized_model.compile(optimizer=opt, loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a4811f1-408e-4bac-9f07-fb9c7d531990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:34:18.793110: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 13 of 30\n",
      "2024-07-01 12:34:24.644195: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 7.8338 - sprout_loss: 1.5790 - peeled_loss: 1.5481 - rotten_loss: 1.5799 - double_loss: 1.6105 - background_loss: 1.5164 - sprout_iou_score: 0.2514 - sprout_f1-score: 0.3395 - sprout_precision: 0.5002 - sprout_recall: 0.5067 - peeled_iou_score: 0.2603 - peeled_f1-score: 0.3591 - peeled_precision: 0.5006 - peeled_recall: 0.5073 - rotten_iou_score: 0.2559 - rotten_f1-score: 0.3496 - rotten_precision: 0.5002 - rotten_recall: 0.5067 - double_iou_score: 0.2508 - double_f1-score: 0.3340 - double_precision: 0.5000 - double_recall: 0.7508 - background_iou_score: 0.3273 - background_f1-score: 0.4762 - background_precision: 0.5267 - background_recall: 0.5460 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 12:34:45.172987: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 13 of 30\n",
      "2024-07-01 12:34:50.561188: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 28 of 30\n",
      "2024-07-01 12:34:50.561255: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 52s 24s/step - loss: 7.8338 - sprout_loss: 1.5790 - peeled_loss: 1.5481 - rotten_loss: 1.5799 - double_loss: 1.6105 - background_loss: 1.5164 - sprout_iou_score: 0.2514 - sprout_f1-score: 0.3395 - sprout_precision: 0.5002 - sprout_recall: 0.5067 - peeled_iou_score: 0.2603 - peeled_f1-score: 0.3591 - peeled_precision: 0.5006 - peeled_recall: 0.5073 - rotten_iou_score: 0.2559 - rotten_f1-score: 0.3496 - rotten_precision: 0.5002 - rotten_recall: 0.5067 - double_iou_score: 0.2508 - double_f1-score: 0.3340 - double_precision: 0.5000 - double_recall: 0.7508 - background_iou_score: 0.3273 - background_f1-score: 0.4762 - background_precision: 0.5267 - background_recall: 0.5460 - val_loss: 6.9533 - val_sprout_loss: 1.3444 - val_peeled_loss: 1.4795 - val_rotten_loss: 1.3161 - val_double_loss: 1.4794 - val_background_loss: 1.3338 - val_sprout_iou_score: 0.2887 - val_sprout_f1-score: 0.3673 - val_sprout_precision: 0.4998 - val_sprout_recall: 0.4800 - val_peeled_iou_score: 0.2542 - val_peeled_f1-score: 0.3707 - val_peeled_precision: 0.4949 - val_peeled_recall: 0.4804 - val_rotten_iou_score: 0.3075 - val_rotten_f1-score: 0.4028 - val_rotten_precision: 0.4970 - val_rotten_recall: 0.4814 - val_double_iou_score: 0.2439 - val_double_f1-score: 0.3277 - val_double_precision: 0.5000 - val_double_recall: 0.7437 - val_background_iou_score: 0.3332 - val_background_f1-score: 0.4881 - val_background_precision: 0.5117 - val_background_recall: 0.5159 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H = quantized_model.fit(train_data,\n",
    "                  epochs=1,\n",
    "                  validation_data=val_data,\n",
    "                  callbacks=[tensorboard_callback, LR_Reduce_callback, model_ckpt2],\n",
    "                  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26444b77-6bf1-4c08-bbfa-7a9684dd30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# # Function to represent the dataset for calibration\n",
    "# def representative_data_gen():\n",
    "#     for input_value in tf.data.Dataset.from_tensor_slices(train_data).batch(1).take(10):\n",
    "#         yield [input_value]\n",
    "\n",
    "# # Convert the model to a TFLite model\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model)\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.representative_dataset = representative_data_gen\n",
    "# converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# converter.inference_input_type = tf.uint8  # or tf.int8\n",
    "# converter.inference_output_type = tf.uint8  # or tf.int8\n",
    "\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model\n",
    "# with open('quantized_model.tflite2', 'wb') as f:\n",
    "#     f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e93ee-9c33-421a-baa0-4717fe1799db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13f057a8-544f-46a2-add3-c837bcedc5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu41kl8ri/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpu41kl8ri/assets\n",
      "/home/agrograde/.local/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2024-07-01 12:35:15.800715: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2024-07-01 12:35:15.800750: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2024-07-01 12:35:15.801301: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpu41kl8ri\n",
      "2024-07-01 12:35:15.831807: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2024-07-01 12:35:15.831856: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpu41kl8ri\n",
      "2024-07-01 12:35:15.912183: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2024-07-01 12:35:15.945477: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2024-07-01 12:35:16.646758: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpu41kl8ri\n",
      "2024-07-01 12:35:16.820627: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 1019330 microseconds.\n",
      "2024-07-01 12:35:17.230019: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "float_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d041d27-082e-479a-ac52-2819f291b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tflite_model.tflite\",\"wb\") as f:\n",
    "    f.write(float_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30cd95-daae-407f-a76c-169520001433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2197e7-9694-464a-a217-945a3a9b3496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f504a38-eb05-47e6-93be-fdadbc2955a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b5c14-a325-49b3-a59b-a2d45c151c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7f206-b8dc-41e0-83f1-cf0937161686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d51ce2-7718-4633-a2c7-1d9ebe3c87e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbde11f-eeed-4f1f-973e-96b3a0a75f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd482be-ba9a-47d1-a863-f28977a653e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed6614-6f2c-4586-9757-833e17e4a1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9ca8c-cd77-4f43-8585-e35f9b42453a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095dd66c-66a2-40f5-b5bb-86bd70f909f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_model_optimization as tfmot``````````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea43a0af-7c26-4a15-add9-0113770ce3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quntize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6335c54-e880-448a-908b-a62b734c0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #build model\n",
    "# import segmentation_models as sm\n",
    "# from keras.layers import *\n",
    "# from keras import layers\n",
    "# from keras.models import Model\n",
    "# import tensorflow_model_optimization as tfmot\n",
    "\n",
    "# def SEModule(input, ratio, out_dim):\n",
    "#     x = GlobalAveragePooling2D()(input)\n",
    "#     excitation = Dense(units=out_dim // ratio)(x)\n",
    "#     excitation = Activation('relu')(excitation)\n",
    "#     excitation = Dense(units=out_dim)(excitation)\n",
    "#     excitation = Activation('sigmoid')(excitation)\n",
    "#     excitation = Reshape((1, 1, out_dim))(excitation)\n",
    "#     scale = multiply([input, excitation])\n",
    "#     return scale\n",
    "\n",
    "# def SEUnet(nClasses, input_height=224, input_width=224):\n",
    "#     inputs = Input(shape=(input_height, input_width, 3))\n",
    "    \n",
    "#     quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "\n",
    "#     conv1 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(inputs)\n",
    "    \n",
    "#     conv1 = BatchNormalization()(conv1)\n",
    "#     conv1 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(inputs)\n",
    "#     conv1 = BatchNormalization()(conv1)\n",
    "#     # SE\n",
    "#     conv1 = SEModule(conv1, 4, 16)\n",
    "\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "#     conv2 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool1)\n",
    "#     conv2 = BatchNormalization()(conv2)\n",
    "#     conv2 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv2)\n",
    "#     conv2 = BatchNormalization()(conv2)\n",
    "    \n",
    "#     # SE\n",
    "#     conv2 = SEModule(conv2, 8, 32)\n",
    "\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "#     conv3 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool2)\n",
    "#     conv3 = BatchNormalization()(conv3)\n",
    "#     conv3 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv3)\n",
    "#     conv3 = BatchNormalization()(conv3)\n",
    "    \n",
    "#     # SE\n",
    "#     conv3 = SEModule(conv3, 8, 64)\n",
    "\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "#     conv4 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool3)\n",
    "#     conv4 = BatchNormalization()(conv4)\n",
    "#     conv4 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv4)\n",
    "#     conv4 = BatchNormalization()(conv4)\n",
    "    \n",
    "#     # SE\n",
    "#     conv4 = SEModule(conv4, 16, 128)\n",
    "\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "#     conv5 = quantize_annotate_layer(\n",
    "#         Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(pool4)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "#     conv5 = quantize_annotate_layer(\n",
    "#         Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv5)\n",
    "#     conv5 = BatchNormalization()(conv5)\n",
    "    \n",
    "#     # SE\n",
    "#     conv5 = SEModule(conv5, 16, 256)\n",
    "\n",
    "#     up6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv5))\n",
    "#     up6 = BatchNormalization()(up6)\n",
    "#     merge6 = concatenate([conv4, up6], axis=3)\n",
    "#     conv6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge6)\n",
    "#     conv6 = BatchNormalization()(conv6)\n",
    "#     conv6 = quantize_annotate_layer(\n",
    "#         Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv6)\n",
    "#     conv6 = BatchNormalization()(conv6)\n",
    "    \n",
    "#     # SE\n",
    "#     conv6 = SEModule(conv6, 16, 128)\n",
    "\n",
    "#     up7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv6))\n",
    "#     up7 = BatchNormalization()(up7)\n",
    "#     merge7 = concatenate([conv3, up7], axis=3)\n",
    "#     conv7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge7)\n",
    "#     conv7 = BatchNormalization()(conv7)\n",
    "#     conv7 = quantize_annotate_layer(\n",
    "#         Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv7)\n",
    "#     conv7 = BatchNormalization()(conv7)\n",
    "    \n",
    "#     # SE\n",
    "#     conv7 = SEModule(conv7, 8, 64)\n",
    "\n",
    "#     up8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv7))\n",
    "#     up8 = BatchNormalization()(up8)\n",
    "#     merge8 = concatenate([conv2, up8], axis=3)\n",
    "#     conv8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge8)\n",
    "#     conv8 = BatchNormalization()(conv8)\n",
    "#     conv8 = quantize_annotate_layer(\n",
    "#         Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv8)\n",
    "#     conv8 = BatchNormalization()(conv8)\n",
    "    \n",
    "#     # SE\n",
    "#     conv8 = SEModule(conv8, 4, 32)\n",
    "\n",
    "#     up9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 2, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(UpSampling2D(size=(2, 2))(conv8))\n",
    "#     up9 = BatchNormalization()(up9)\n",
    "#     merge9 = concatenate([conv1, up9], axis=3)\n",
    "#     conv9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(merge9)\n",
    "#     conv9 = BatchNormalization()(conv9)\n",
    "#     conv9 = quantize_annotate_layer(\n",
    "#         Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')\n",
    "#     )(conv9)\n",
    "#     conv9 = BatchNormalization()(conv9)\n",
    "    \n",
    "#     # SE\n",
    "#     conv9 = SEModule(conv9, 2, 16)\n",
    "\n",
    "#     conv10 = quantize_annotate_layer(\n",
    "#         Conv2D(nClasses, (3, 3), padding='same')\n",
    "#     )(conv9)\n",
    "#     conv10 = BatchNormalization()(conv10)\n",
    "\n",
    "#     outputHeight = Model(inputs, conv10).output_shape[1]\n",
    "#     outputWidth = Model(inputs, conv10).output_shape[2]\n",
    "\n",
    "#     out = Reshape((outputHeight * outputWidth, nClasses))(conv10)\n",
    "#     out = Activation('softmax')(out)\n",
    "\n",
    "#     model = Model(inputs, out)\n",
    "#     model.outputHeight = outputHeight\n",
    "#     model.outputWidth = outputWidth\n",
    "\n",
    "#     return model\n",
    "\n",
    "# model1 = SEUnet(nClasses=5)\n",
    "# model1.summary()\n",
    "\n",
    "# x = model1.get_layer(index=-3).output\n",
    "\n",
    "# # folder=[\"Sprout\",\"Black_smut\",\"Rotten\",\"Background\"]\n",
    "# out0 = Conv2D(2, (1, 1), activation='softmax',name='sprout')(x)\n",
    "# out1 = Conv2D(2, (1, 1), activation='softmax',name='peeled')(x)\n",
    "# out2 = Conv2D(2, (1, 1), activation='softmax',name='rotten')(x)\n",
    "# out3 = Conv2D(2, (1, 1), activation='softmax',name='double')(x)\n",
    "# out4 = Conv2D(2, (1, 1), activation='softmax',name='background')(x)\n",
    "\n",
    "\n",
    "# model_new = Model(inputs = model1.input,outputs = [out0,out1,out2,out3,out4])\n",
    "# model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47089ca9-9c14-4145-851c-10ff3772a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_new.load_weights(r\"/home/agrograde/Desktop/quantization/quantized/onin_28th_june_spplrobg_28thjune2024_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12e9d2-b736-4532-9d03-61b6961c2dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af86f0-792d-4f44-80b7-57d81bcdbcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd627031-1b99-4513-9e5b-70cf6f1aaecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36cd597-99f9-4f6a-aac8-22f0abbeaaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6e7d0-b538-4eaa-84d2-3a0be0cf3d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ce6ba-47af-4523-bf93-f572456e64d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225235e9-722e-4254-9d04-0e808c8f27d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f2e1a-fd29-49db-a916-184faf46c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ef453-1221-4620-a83c-b7a0ccfb9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, float_file = tempfile.mkstemp('.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bffa212-7a17-4322-85f9-914a60a21c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(float_file, 'wb') as f:\n",
    "  f.write(float_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a8afa-a5eb-4880-a2fd-657bcd7a5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70579553-06ae-49c6-908c-8ee466a54941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c697641-e4b3-4d64-94ae-88fa88bea030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431626d-e7be-416a-bb16-b995bcdd4849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99703c1b-94cc-4419-a915-c7e0ab72205f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210e77d-9bb2-4a7b-80b1-b90353ebc8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e04c22-891e-470e-b2b3-7a7c892861f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f66a3c-aed2-41df-a3d2-897b661cd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43737a62-d688-4ddd-829b-cfeb57353643",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_aware_model = quantize_model(model_new)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_model_optimization.python.core.quantization.keras import quantize_config\n",
    "#from tensorflow_model_optimization.python.core.quantization.keras import quantize_annotate_layer\n",
    "from tensorflow_model_optimization.python.core.quantization.keras import quantize_apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc689c1a-5f0c-4706-a50c-ff0c52a04978",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-model-optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125af0e0-8574-42f4-b30e-645faf8cb71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f357b-126b-4e6d-bd33-c3a1af4437bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fff7a2-7bdd-440a-8818-cb631f954356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95dbab5-6d4e-4835-aa3b-3db86aa04ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73cf99-4b08-4bc7-9bf0-c323abd3819f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c8002a-7e9f-4c05-8f9c-03ecb84c34e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c78c3-831c-45c6-abfc-f0b8d175b2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9633d5-92fe-4060-9fc7-c4a88cd3ff4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722448c-82fb-49dd-9868-c6b327046187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8b5d4-7971-4947-8068-2924c616222d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add02477-40ce-4915-aa74-7eb3af815fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c319a-4ae5-4f7d-9406-87b31e3fbef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a8b67-ea5a-4ebe-9fb9-0b67373e20e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ededbdb-a01c-460e-84a3-654c14f9bf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396472e0-730d-4fe9-9e5f-58aa370648c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b566b2aa-0c85-489c-ae15-a169c7d0a6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37c9fb-2cc2-48c4-b367-da966dea1167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8410e4-4a57-4ce6-bdda-04f57ff4680f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a840d4-5f95-47e3-880f-79a4e1107cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17166125-cf5f-4c60-bcab-ade7677229cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac164f07-9bb2-4c83-8c34-ab949cad3a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531baedd-c582-47aa-978c-85a4088b347a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf16437-f280-4c6e-9403-428bb9bd2009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa155ba-6a5f-444c-ab85-84902001076d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f539fa5-1868-4b07-b53e-2f2ff9e0cb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7eb10-7b4e-4693-8720-2bc67eb0da7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff10a3a-d76e-4977-8256-11b9f16e64d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2fdc98-31ad-4bad-b476-773ea3d23cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc1856-d54b-46e0-81a6-d0b15c014b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd8c3d-5b60-4e4f-96d7-1fa11caab98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b57121-4ac0-494c-92c7-4b927e6a9687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c18d3-5b18-4747-919e-1e48acb6fc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59630b52-4ff7-46d4-8a58-41463351fbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafd793-f43b-403d-94ed-d5dbb63fd159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda177b5-f393-4ffa-8e59-5f17398d78ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea2af3-f426-4b35-8335-e0fb68396876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b3447-85aa-487a-bf0b-12779f0b770f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e8089-25e3-4357-8ac8-ff7d714d005f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64bba1-0c93-48bd-ab81-498ca90654e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0fa2d1-cf20-4dfd-a860-033182d030d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e37d7-68d2-4f01-956c-b06b3cfe7e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c04fc0-3d64-4a2d-9aac-c2dd02cfe786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b162051d-3615-4d7d-886c-7d6d95e94505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42743a-250f-452c-9a5a-29710deddb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d2742-161a-44d0-a7d2-4afbfff4d051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ab83a-dfeb-48f2-9b17-5c3adc341f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0da0c8-be59-4af6-8f26-50a048ba6161",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60aa0e-7b30-43c8-b8cb-82417698e8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b9419-455d-4f7f-bf3b-c1fc0dc652d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16a174-7467-485d-9b3e-4065c07d0833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726f24b-4a56-4134-ab4a-eecbdd4b18e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa79a1b9-b236-46cc-a369-4bc8dcc4bb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17263ddb-fbab-48d9-b78e-8bc64157bb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4af87-e4bf-4beb-8920-abf19cdd82b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697966df-f5a4-4c63-b3ac-7e97d1016671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a14b38-59d3-416a-8e81-6cbaf46baded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75188d5e-2f75-45d5-bc7b-b318071f5e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac8fd43-4a50-42ff-8739-53cfaa517eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffa03a-bf98-48cf-873c-00b4dccf682b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2187c739-612a-48a4-8158-f8ccc60c07c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2054e48-5d8d-4ea7-80b2-03620cd3d7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d88618-ff46-42d7-8ce8-f3c78fa5e036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee24d7f-69ac-4025-a90f-da7a1ed34d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e077e-3409-469c-880f-a4adac2b536f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d185b-ccba-45b6-af43-5abb6872e08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340a17d-4eb7-4150-a7c3-8a35edb015be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8fd17-ccc9-4a53-bba4-57a752d83699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d645c5-9169-4dd1-a08b-ecd1837a7ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf07ee31-1d49-461e-b8c9-a727a0473652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aef3292-e3c0-465b-bca6-56340c5a980c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b21ef-55cd-4215-8cc7-526ace5ffe10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f521ea53-283e-4b45-970e-b8b65f79241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae40eaa-cc8c-407a-979a-930ed6623fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166022e-5e4f-4e9b-b15b-a9b758e08bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468e56e-44a0-414e-a354-3b867dd0aa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31522bef-608d-4278-94bc-8fcb7923b324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cadc5e-b760-4f2e-a937-2543062e9d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ced2b7-9aa5-4138-8b41-a74f45ed1ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94baaa-fac7-45de-bdd0-ce9951f8bdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044705f-10c4-4c1f-94f2-16a07d349b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d140fb-c114-44b6-a431-acf200a9886a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c1feb-03b9-4a30-80e7-972024d9deaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fffb23-b163-4d83-9b32-0a44212c615b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec585e50-7f78-488f-801c-d9b4c6be285d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c355b7-9ec5-49c9-82c6-0177c002b373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad84770-18a8-434d-b258-2500504bba32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9f810-6e33-4d17-95b2-46e43d198a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23634407-e282-4840-bdaf-c0556af84e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4132c52-7977-4cf2-bce5-5e5e5b4407fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5118a-3437-44eb-b239-cac5cab1dd50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c3057-af15-4ca1-bca8-aea44282bb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207fa24d-f628-4f9f-81f8-649997c6da37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe58a1-45dd-4a09-a19b-b5332ed07041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83dff4-6838-4328-af75-c9572a752e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f0f6963-50f4-4697-952e-3511af3be37e",
   "metadata": {},
   "source": [
    "### train,val,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084a257-e7e0-44c0-8ced-ee800f4aeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y1, y2, y3, y4, y5, batch_size, train_split=0.8, val_split=0.1):\n",
    "    # Combine inputs and targets into a single dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y1, y2, y3, y4, y5))\n",
    "    \n",
    "    # Shuffle the dataset with a buffer size of 1000\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    \n",
    "    # Apply any necessary preprocessing to each sample (e.g., normalization, resizing)\n",
    "    dataset = dataset.map(preprocess)\n",
    "    \n",
    "    # Calculate the number of samples for each split\n",
    "    total_samples = len(x)\n",
    "    train_samples = int(total_samples * train_split)\n",
    "    val_samples = int(total_samples * val_split)\n",
    "    \n",
    "    # Split dataset into training and validation sets\n",
    "    train_dataset = dataset.take(train_samples)\n",
    "    val_dataset = dataset.skip(train_samples).take(val_samples)\n",
    "    \n",
    "    # Split inputs and targets into separate datasets\n",
    "    train_images = train_dataset.map(lambda x, *y: x)\n",
    "    train_sprout = train_dataset.map(lambda x, *y: y[0])\n",
    "    train_peeled = train_dataset.map(lambda x, *y: y[1])\n",
    "    train_rotten = train_dataset.map(lambda x, *y: y[2])\n",
    "    train_double = train_dataset.map(lambda x, *y: y[3])\n",
    "    train_background = train_dataset.map(lambda x, *y: y[4])\n",
    "    \n",
    "    # For validation dataset\n",
    "    val_images = val_dataset.map(lambda x, *y: x)\n",
    "    val_sprout = val_dataset.map(lambda x, *y: y[0])\n",
    "    val_peeled = val_dataset.map(lambda x, *y: y[1])\n",
    "    val_rotten = val_dataset.map(lambda x, *y: y[2])\n",
    "    val_double = val_dataset.map(lambda x, *y: y[3])\n",
    "    val_background = val_dataset.map(lambda x, *y: y[4])\n",
    "    \n",
    "    # Batch the datasets\n",
    "    train_images = train_images.batch(batch_size)\n",
    "    train_sprout = train_sprout.batch(batch_size)\n",
    "    train_peeled = train_peeled.batch(batch_size)\n",
    "    train_rotten = train_rotten.batch(batch_size)\n",
    "    train_double = train_double.batch(batch_size)\n",
    "    train_background = train_background.batch(batch_size)\n",
    "    \n",
    "    val_images = val_images.batch(batch_size)\n",
    "    val_sprout = val_sprout.batch(batch_size)\n",
    "    val_peeled = val_peeled.batch(batch_size)\n",
    "    val_rotten = val_rotten.batch(batch_size)\n",
    "    val_double = val_double.batch(batch_size)\n",
    "    val_background = val_background.batch(batch_size)\n",
    "    \n",
    "    # Prefetch data for improved performance\n",
    "    train_images = train_images.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_sprout = train_sprout.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_peeled = train_peeled.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_rotten = train_rotten.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_double = train_double.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_background = train_background.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_images = val_images.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_sprout = val_sprout.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_peeled = val_peeled.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_rotten = val_rotten.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_double = val_double.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_background = val_background.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return (train_images, train_sprout, train_peeled, train_rotten, train_double, train_background), \\\n",
    "           (val_images, val_sprout, val_peeled, val_rotten, val_double, val_background)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69858c4-9502-4048-bc8b-7d8d55e3840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_sprout, train_peeled, train_rotten, train_double, train_background), \\\n",
    "(val_images, val_sprout, val_peeled, val_rotten, val_double, val_background) = \\\n",
    "    tf_dataset(images, sprout, peeled, rotten, double, background, batch_size=16, \n",
    "               train_split=0.8, val_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f19040-23f7-468b-83b9-ffa684af1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_batch(images_batch, masks_batch, batch_size=16):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        img = images_batch[i]\n",
    "        mask_sprout = masks_batch[0][i][:, :, 1]\n",
    "        mask_peeled = masks_batch[1][i][:, :, 1]\n",
    "        mask_rotten = masks_batch[2][i][:, :, 1]\n",
    "        mask_double = masks_batch[3][i][:, :, 1]\n",
    "        mask_background = masks_batch[4][i][:, :, 1]\n",
    "        \n",
    "        plt.subplot(batch_size, 6, i*6 + 1)\n",
    "        plt.imshow(img.astype(np.uint8))\n",
    "        plt.title('Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(batch_size, 6, i*6 + 2)\n",
    "        plt.imshow(mask_sprout, cmap='gray')\n",
    "        plt.title('Sprout Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(batch_size, 6, i*6 + 3)\n",
    "        plt.imshow(mask_peeled, cmap='gray')\n",
    "        plt.title('Peeled Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(batch_size, 6, i*6 + 4)\n",
    "        plt.imshow(mask_rotten, cmap='gray')\n",
    "        plt.title('Rotten Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(batch_size, 6, i*6 + 5)\n",
    "        plt.imshow(mask_double, cmap='gray')\n",
    "        plt.title('Double Mask')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(batch_size, 6, i*6 + 6)\n",
    "        plt.imshow(mask_background, cmap='gray')\n",
    "        plt.title('Background Mask')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd6c7a-cea4-4f13-870d-d8322a49dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first batch from the dataset\n",
    "for batch in train_images.take(1):\n",
    "    images_batch = batch.numpy()\n",
    "\n",
    "masks_batches = []\n",
    "for dataset in [train_sprout, train_peeled, train_rotten, train_double, train_background]:\n",
    "    for batch in dataset.take(1):\n",
    "        masks_batches.append(batch.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f8fe3-3a2d-41a9-80bb-ed93c42993e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the first batch\n",
    "visualize_batch(images_batch, masks_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main utility functions for model\n",
    "def dsc(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dsc(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def iou_score(gt, pr, class_weights=1., smooth=1, per_image=True, threshold=None):\n",
    "    '''\n",
    "    input：\n",
    "        gt: ground truth 4D keras tensor (B, H, W, C)\n",
    "        pr: prediction 4D keras tensor (B, H, W, C)\n",
    "        class_weights: 1. or list of class weights, len(weights) = C\n",
    "        smooth: value to avoid division by zero\n",
    "        per_image: if ``True``, metric is calculated as mean over images in batch (B),\n",
    "            else over whole batch\n",
    "        threshold: value to round predictions (use ``>`` comparison), \n",
    "        if ``None`` prediction prediction will not be round\n",
    "    output：\n",
    "        IoU/Jaccard score in range [0, 1]\n",
    "    '''\n",
    "    if per_image:\n",
    "        axes = [1, 2]\n",
    "    else:\n",
    "        axes = [0, 1, 2]\n",
    "        \n",
    "    if threshold is not None:\n",
    "        pr = tf.greater(pr, threshold)\n",
    "        pr = tf.cast(pr, dtype=tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(gt * pr, axis=axes)\n",
    "    union = tf.reduce_sum(gt + pr, axis=axes) - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "\n",
    "    # mean per image\n",
    "    if per_image:\n",
    "        iou = tf.reduce_mean(iou, axis=0)\n",
    "\n",
    "    # weighted mean per class\n",
    "    iou = tf.reduce_mean(iou * class_weights)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "import segmentation_models as sm\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def SEModule(input, ratio, out_dim):\n",
    "    # bs, c, h, w\n",
    "    x = GlobalAveragePooling2D()(input)\n",
    "    excitation = Dense(units=out_dim // ratio)(x)\n",
    "    excitation = Activation('relu')(excitation)\n",
    "    excitation = Dense(units=out_dim)(excitation)\n",
    "    excitation = Activation('sigmoid')(excitation)\n",
    "    excitation = Reshape((1, 1, out_dim))(excitation)\n",
    "    scale = multiply([input, excitation])\n",
    "    return scale\n",
    "\n",
    "\n",
    "def SEUnet(nClasses, input_height=224, input_width=224):\n",
    "    inputs = Input(shape=(input_height, input_width, 3))\n",
    "    conv1 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "\n",
    "    conv1 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "\n",
    "    # se\n",
    "    conv1 = SEModule(conv1, 4, 16)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "\n",
    "    conv2 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "\n",
    "    # se\n",
    "    conv2 = SEModule(conv2, 8, 32)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    conv3 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    # se\n",
    "    conv3 = SEModule(conv3, 8, 64)\n",
    "\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    conv4 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    # se\n",
    "    conv4 = SEModule(conv4, 16, 128)\n",
    "\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(256,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(256,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    # se\n",
    "    conv5 = SEModule(conv5, 16, 256)\n",
    "\n",
    "    up6 = Conv2D(128,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv5))\n",
    "    up6 = BatchNormalization()(up6)\n",
    "\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    conv6 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    # se\n",
    "    conv6 = SEModule(conv6, 16, 128)\n",
    "\n",
    "    up7 = Conv2D(64,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv6))\n",
    "    up7 = BatchNormalization()(up7)\n",
    "\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    conv7 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    # se\n",
    "    conv7 = SEModule(conv7, 8, 64)\n",
    "\n",
    "    up8 = Conv2D(32,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv7))\n",
    "    up8 = BatchNormalization()(up8)\n",
    "\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    conv8 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    # se\n",
    "    conv8 = SEModule(conv8, 4, 32)\n",
    "\n",
    "    up9 = Conv2D(16,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv8))\n",
    "    up9 = BatchNormalization()(up9)\n",
    "\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    conv9 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    # se\n",
    "    conv9 = SEModule(conv9, 2, 16)\n",
    "\n",
    "    conv10 = Conv2D(nClasses, (3, 3), padding='same')(conv9)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "\n",
    "    outputHeight = Model(inputs, conv10).output_shape[1]\n",
    "    outputWidth = Model(inputs, conv10).output_shape[2]\n",
    "\n",
    "    out = (Reshape((outputHeight * outputWidth, nClasses)))(conv10)\n",
    "    out = Activation('softmax')(out)\n",
    "\n",
    "    model = Model(inputs,out)\n",
    "    model.outputHeight = outputHeight\n",
    "    model.outputWidth = outputWidth\n",
    "\n",
    "    return model\n",
    "\n",
    "model1 = SEUnet(nClasses=5)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649574ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model1.get_layer(index=-3).output\n",
    "\n",
    "# folder=[\"Sprout\",\"Black_smut\",\"Rotten\",\"Background\"]\n",
    "out0 = Conv2D(2, (1, 1), activation='softmax',name='sprout')(x)\n",
    "out1 = Conv2D(2, (1, 1), activation='softmax',name='peeled')(x)\n",
    "out2 = Conv2D(2, (1, 1), activation='softmax',name='rotten')(x)\n",
    "out3 = Conv2D(2, (1, 1), activation='softmax',name='double')(x)\n",
    "out4 = Conv2D(2, (1, 1), activation='softmax',name='background')(x)\n",
    "\n",
    "\n",
    "model_new = Model(inputs = model1.input,outputs = [out0,out1,out2,out3,out4])\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bdf89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738e589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26002f83-2398-4ed6-84a5-cbcc44ddba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models.metrics import  f1_score,precision,recall\n",
    "from segmentation_models.metrics import  f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6adab-c409-4330-a14d-5ba00c01beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60343213-86b9-4636-92a0-16b8bce1386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_name = 'onin_24th_jan_spplrobg'\n",
    "date = '24thdec2024'\n",
    "learning_rate = 0.001\n",
    "# num_epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the optimizer\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Define losses, metrics, and loss weights\n",
    "losses = {\"sprout\": sm.losses.bce_jaccard_loss, \"peeled\": sm.losses.bce_jaccard_loss, \"rotten\": sm.losses.bce_jaccard_loss,\"double\": sm.losses.bce_jaccard_loss,\"background\": sm.losses.bce_jaccard_loss}\n",
    "metrics = {\"sprout\": [iou_score, f1_score,precision,recall], \"peeled\": [iou_score, f1_score,precision,recall], \"rotten\": [iou_score, f1_score,precision,recall],\"double\": [iou_score, f1_score,precision,recall], \"background\": [iou_score, f1_score,precision,recall]}\n",
    "loss_weights = {\"sprout\": 1.0, \"peeled\": 1.0, \"rotten\": 1.0, \"double\": 1.0, \"background\": 2.0}\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "LR_Reduce_callback = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto')\n",
    "model_ckpt1 = ModelCheckpoint(model_name+'_'+date+'.h5', monitor='loss', save_weights_only=False,save_best_only=True, period=1)\n",
    "model_ckpt2 = ModelCheckpoint(model_name+'_'+date+'_weights.h5', monitor='loss', save_weights_only=True,save_best_only=True, period=1)\n",
    "# reduce_rl_plateau = CustomReduceLRoP(patience=4, \n",
    "#                               verbose=1, \n",
    "#                               optim_lr=opt.learning_rate, \n",
    "#                               mode='auto',\n",
    "#                               factor=0.1)\n",
    "# Compile the model using the initialized optimizer\n",
    "model_new.compile(optimizer=opt, loss=losses, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914752c-ebc1-4949-a43b-fd797718459c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb9699cf-f504-464c-bb76-a97d6b68dfb2",
   "metadata": {},
   "source": [
    "### for training and validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962250e-cf69-4154-9dc8-7718fe803fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    \"sprout\": train_sprout,\n",
    "    \"peeled\": train_peeled,\n",
    "    \"rotten\": train_rotten,\n",
    "    \"double\": train_double,\n",
    "    \"background\": train_background\n",
    "}\n",
    "val_labels_dict = {\n",
    "    \"sprout\": val_sprout,\n",
    "    \"peeled\": val_peeled,\n",
    "    \"rotten\": val_rotten,\n",
    "    \"double\": val_double,\n",
    "    \"background\": val_background\n",
    "}\n",
    "val_data = tf.data.Dataset.zip((val_images, val_labels_dict)) \n",
    "# Zip images and label dictionary into a single dataset\n",
    "train_data = tf.data.Dataset.zip((train_images, labels_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b257aca-040f-4add-af43-385e729a1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H = model_new.fit(train_data,\n",
    "                  epochs=2,\n",
    "                  validation_data=val_data,\n",
    "                  callbacks=[tensorboard_callback, LR_Reduce_callback, model_ckpt1, model_ckpt2],\n",
    "                  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a53dd4-e4d1-4229-8209-e29d400d5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cad218-9625-4317-bf34-0fc0e11ece05",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ecf80-b6d1-4a8b-8901-efa256f9df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e013a84-168c-4017-8b88-302c94bc607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard         \n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56781e04-ee3e-41fd-a595-71fad18682ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graphs\n",
    "# folder=['holes\":1.0,\"potato\": 1.0,\"rotten\": 1.0,\"cuts\"]\n",
    "fig, (ax0,ax1, ax2, ax3, ax4,ax5) = plt.subplots(1, 6, figsize = (41, 10))\n",
    "# fig, (ax0,ax1, ax2) = plt.subplots(1, 3, figsize = (17, 5))\n",
    "\n",
    "ax0.plot(H.history['loss'], '-', label = 'Loss')\n",
    "ax0.plot(H.history['val_loss'], '-', label = 'Validation Loss')\n",
    "ax0.legend()\n",
    "plt.savefig('loss.png')\n",
    "\n",
    "ax1.plot(100*np.array(H.history['Sprout_iou_score']), '-', \n",
    "         label = 'Accuracy_Sprout')\n",
    "ax1.plot(100*np.array(H.history['val_Sprout_iou_score']), '-',\n",
    "         label = 'Validation Accuracy_Sprout')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax4.plot(100*np.array(H.history['Peeled_iou_score']), '-', \n",
    "         label = 'Accuracy_Peeled')\n",
    "ax4.plot(100*np.array(H.history['val_Peeled_iou_score']), '-',\n",
    "         label = 'Validation Accuracy_Peeled')\n",
    "ax4.legend()\n",
    "\n",
    "\n",
    "\n",
    "ax2.plot(100*np.array(H.history['Rotten_iou_score']), '-', \n",
    "         label = 'Accuracy_Rotten')\n",
    "ax2.plot(100*np.array(H.history['val_Rotten_iou_score']), '-',\n",
    "         label = 'Validation Accuracy_Rotten')\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "ax3.plot(100*np.array(H.history['Background_iou_score']), '-', \n",
    "         label = 'Accuracy_Background')\n",
    "ax3.plot(100*np.array(H.history['val_Background_iou_score']), '-',\n",
    "         label = 'Validation Accuracy_Background')\n",
    "ax3.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ax4.plot(100*np.array(H.history['Peeled_iou_score']), '-', \n",
    "#          label = 'Accuracy_Peeled')\n",
    "# ax4.plot(100*np.array(H.history['val_Peeled_iou_score']), '-',\n",
    "#          label = 'Validation Accuracy_Peeled')\n",
    "# ax4.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a893a-34eb-4074-84e0-944f7e716415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e56c96-f16f-42eb-9cdb-74baea7902e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b720b9c-9065-4453-b6e5-6f83955c4709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b072b4-6431-4a14-85ef-dea89e9abf7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe1d25-377a-429a-96fb-ac3f3565d90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a2ee6-ea0c-4a63-865b-90b9c33a9871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fee2d6-f37e-4842-a667-1377da2e18bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac3ad9-e37f-4e76-98b4-27dc168d11c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0f6ae-9695-4e7f-9f92-42d7d6b1377d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57483311-c074-4a85-aab3-25dd655390fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70138b-681b-4edf-b54c-f4ef69b87084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3b902-026f-483b-b804-91d25af07c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea4337-907d-439e-a888-9823eb59fab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058acdb-f5ab-4338-b903-3665ccf461aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae9d11-47e0-4dde-8ba3-436e1b47f8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac972d5c-b17a-4602-8a39-0e18e3e5c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "matrix_dict = {\"train_loss\":[],\"val_loss\":[],train.....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae5edc-72b5-46b9-865e-60700ec984f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_losses = []\n",
    "train_ious_sprout = []\n",
    "train_ious_peeled = []\n",
    "train_ious_rotten = []\n",
    "train_ious_double = []\n",
    "train_ious_background = []\n",
    "\n",
    "train_f1_scores_sprout = []\n",
    "train_f1_scores_peeled = []\n",
    "train_f1_scores_rotten = []\n",
    "train_f1_scores_double = []\n",
    "train_f1_scores_background = []\n",
    "\n",
    "\n",
    "val_losses = []\n",
    "val_ious_sprout = []\n",
    "val_ious_peeled = []\n",
    "val_ious_rotten = []\n",
    "val_ious_double = []\n",
    "val_ious_background = []\n",
    "\n",
    "val_f1_scores_sprout = []\n",
    "val_f1_scores_peeled = []\n",
    "val_f1_scores_rotten = []\n",
    "val_f1_scores_double = []\n",
    "val_f1_scores_background = []\n",
    "\n",
    "train_precisions_sprout = []\n",
    "train_precisions_peeled = []\n",
    "train_precisions_rotten = []\n",
    "train_precisions_double = []\n",
    "train_precisions_background = []\n",
    "\n",
    "train_recalls_sprout = []\n",
    "train_recalls_peeled = []\n",
    "train_recalls_rotten = []\n",
    "train_recalls_double = []\n",
    "train_recalls_background = []\n",
    "\n",
    "val_precisions_sprout = []\n",
    "val_precisions_peeled = []\n",
    "val_precisions_rotten = []\n",
    "val_precisions_double = []\n",
    "val_precisions_background = []\n",
    "\n",
    "val_recalls_sprout = []\n",
    "val_recalls_peeled = []\n",
    "val_recalls_rotten = []\n",
    "val_recalls_double = []\n",
    "val_recalls_background = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "    \n",
    "    # Initialize the training metrics\n",
    "    train_loss = 0.0\n",
    "    train_iou_sprout = 0.0\n",
    "    train_iou_peeled = 0.0\n",
    "    train_iou_rotten = 0.0\n",
    "    train_iou_double = 0.0\n",
    "    train_iou_background = 0.0\n",
    "    train_f1_score_sprout = 0.0\n",
    "    train_f1_score_peeled = 0.0\n",
    "    train_f1_score_rotten = 0.0\n",
    "    train_f1_score_double = 0.0\n",
    "    train_f1_score_background = 0.0\n",
    "    train_precision_sprout = 0.0\n",
    "    train_precision_peeled = 0.0\n",
    "    train_precision_rotten = 0.0\n",
    "    train_precision_double = 0.0\n",
    "    train_precision_background = 0.0\n",
    "    train_recall_sprout = 0.0\n",
    "    train_recall_peeled = 0.0\n",
    "    train_recall_rotten = 0.0\n",
    "    train_recall_double = 0.0\n",
    "    train_recall_background = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # Iterate over the training dataset\n",
    "    for step, (images, sprout_masks, peeled_masks, rotten_masks, double_masks, background_masks) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            sprout_pred, peeled_pred, rotten_pred, double_pred, background_pred = model_new(images, training=True)\n",
    "            sprout_loss = sm.losses.bce_jaccard_loss(sprout_masks, sprout_pred)\n",
    "            peeled_loss = sm.losses.bce_jaccard_loss(peeled_masks, peeled_pred)\n",
    "            rotten_loss = sm.losses.bce_jaccard_loss(rotten_masks, rotten_pred)\n",
    "            double_loss = sm.losses.bce_jaccard_loss(double_masks, double_pred)\n",
    "            background_loss = sm.losses.bce_jaccard_loss(background_masks, background_pred)\n",
    "\n",
    "\n",
    "            iou_sprout = iou_score(sprout_masks, sprout_pred)\n",
    "            iou_peeled = iou_score(peeled_masks, peeled_pred)\n",
    "            iou_rotten = iou_score(rotten_masks, rotten_pred)\n",
    "            iou_double = iou_score(double_masks, double_pred)\n",
    "            iou_background = iou_score(background_masks, background_pred)\n",
    "            \n",
    "            f1_sprout = f1_score(sprout_masks, sprout_pred)\n",
    "            f1_peeled = f1_score(peeled_masks, peeled_pred)\n",
    "            f1_rotten = f1_score(rotten_masks, rotten_pred)\n",
    "            f1_double = f1_score(double_masks, double_pred)\n",
    "            f1_background = f1_score(background_masks, background_pred)\n",
    "            \n",
    "            precision_sprout = precision(sprout_masks, sprout_pred)\n",
    "            precision_peeled = precision(peeled_masks, peeled_pred)\n",
    "            precision_rotten = precision(rotten_masks, rotten_pred)\n",
    "            precision_double = precision(double_masks, double_pred)\n",
    "            precision_background = precision(background_masks, background_pred)\n",
    "            \n",
    "            recall_sprout = recall(sprout_masks, sprout_pred)\n",
    "            recall_peeled = recall(peeled_masks, peeled_pred)\n",
    "            recall_rotten = recall(rotten_masks, rotten_pred)\n",
    "            recall_double = recall(double_masks, double_pred)\n",
    "            recall_background = recall(background_masks, background_pred)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            total_loss = sprout_loss + peeled_loss + rotten_loss + double_loss + background_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, model_new.trainable_variables)\n",
    "        opt.apply_gradients(zip(gradients, model_new.trainable_variables))\n",
    "\n",
    "        \n",
    "        train_loss += total_loss\n",
    "        train_iou_sprout += iou_sprout\n",
    "        train_iou_peeled += iou_peeled\n",
    "        train_iou_rotten += iou_rotten\n",
    "        train_iou_double += iou_double\n",
    "        train_iou_background += iou_background\n",
    "\n",
    "        train_f1_score_sprout += f1_sprout\n",
    "        train_f1_score_peeled += f1_peeled\n",
    "        train_f1_score_rotten += f1_rotten\n",
    "        train_f1_score_double += f1_double\n",
    "        train_f1_score_background += f1_background\n",
    "\n",
    "        train_precision_sprout += precision_sprout\n",
    "        train_precision_peeled += precision_peeled\n",
    "        train_precision_rotten += precision_rotten\n",
    "        train_precision_double += precision_double\n",
    "        train_precision_background += precision_background\n",
    "\n",
    "        train_recall_sprout += recall_sprout\n",
    "        train_recall_peeled += recall_peeled\n",
    "        train_recall_rotten += recall_rotten\n",
    "        train_recall_double += recall_double\n",
    "        train_recall_background += recall_background\n",
    "\n",
    "        if (step + 1) % 40 == 0:\n",
    "            \n",
    "            print(\"Epoch {}/{}, Iteration {}/{} - train_Loss: {:.4f}, train_IOU Sprout: {:.4f}, train_IOU Peeled: {:.4f}, train_IOU Rotten: {:.4f}, train_IOU Double: {:.4f}, train_IOU Background: {:.4f}, train_F1 Score Sprout: {:.4f}, train_F1 Score Peeled: {:.4f}, train_F1 Score Rotten: {:.4f}, train_F1 Score Double: {:.4f}, train_F1 Score Background: {:.4f}, train_Precision Sprout: {:.4f}, train_Precision Peeled: {:.4f}, train_Precision Rotten: {:.4f}, train_Precision Double: {:.4f}, train_Precision Background: {:.4f}, train_Recall Sprout: {:.4f}, train_Recall Peeled: {:.4f}, train_Recall Rotten: {:.4f}, train_Recall double: {:.4f}, train_Recall Background: {:.4f}\".format(epoch + 1, num_epochs, step + 1, len(train_dataset), total_loss.numpy(), iou_sprout,iou_peeled,iou_rotten,iou_double,iou_background,f1_sprout,f1_peeled,f1_rotten,f1_double,f1_background,precision_sprout,precision_peeled,precision_rotten, precision_double,precision_background,recall_sprout,recall_peeled,recall_rotten,recall_double,recall_background))\n",
    "       \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        num_batches += 1\n",
    "    \n",
    "    # Calculate average metrics for the epoch\n",
    "    train_loss /= num_batches\n",
    "    train_iou_sprout /= num_batches\n",
    "    train_iou_peeled /= num_batches\n",
    "    train_iou_rotten /= num_batches\n",
    "    train_iou_double /= num_batches\n",
    "    train_iou_background /= num_batches\n",
    "    \n",
    "    train_f1_score_sprout /= num_batches\n",
    "    train_f1_score_peeled /= num_batches\n",
    "    train_f1_score_rotten /= num_batches\n",
    "    train_f1_score_double /= num_batches\n",
    "    train_f1_score_background /= num_batches\n",
    "\n",
    "    train_precision_sprout /= num_batches\n",
    "    train_precision_peeled /= num_batches\n",
    "    train_precision_rotten /= num_batches\n",
    "    train_precision_double /= num_batches\n",
    "    train_precision_background /= num_batches\n",
    "\n",
    "    train_recall_sprout /= num_batches\n",
    "    train_recall_peeled /= num_batches\n",
    "    train_recall_rotten /= num_batches\n",
    "    train_recall_double /= num_batches\n",
    "    train_recall_background /= num_batches\n",
    "\n",
    "     # Append the values to the respective lists\n",
    "    train_losses.append(train_loss)\n",
    "    train_ious_sprout.append(train_iou_sprout)\n",
    "    train_ious_peeled.append(train_iou_peeled)\n",
    "    train_ious_rotten.append(train_iou_rotten)\n",
    "    train_ious_double.append(train_iou_double)\n",
    "    train_ious_background.append(train_iou_background)\n",
    "    \n",
    "    train_f1_scores_sprout.append(train_f1_score_sprout)\n",
    "    train_f1_scores_peeled.append(train_f1_score_peeled)\n",
    "    train_f1_scores_rotten.append(train_f1_score_rotten)\n",
    "    train_f1_scores_double.append(train_f1_score_double)\n",
    "    train_f1_scores_background.append(train_f1_score_background)\n",
    "    \n",
    "    train_precisions_sprout.append(train_precision_sprout)\n",
    "    train_precisions_peeled.append(train_precision_peeled)\n",
    "    train_precisions_rotten.append(train_precision_rotten)\n",
    "    train_precisions_double.append(train_precision_double)\n",
    "    train_precisions_background.append(train_precision_background)\n",
    "    \n",
    "    train_recalls_sprout.append(train_recall_sprout)\n",
    "    train_recalls_peeled.append(train_recall_peeled)\n",
    "    train_recalls_rotten.append(train_recall_rotten)\n",
    "    train_recalls_double.append(train_recall_double)\n",
    "    train_recalls_background.append(train_recall_background)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Training Loss: {:.4f}, Train_IOU Sprout: {:.4f}, Train_IOU Peeled: {:.4f}, Train_IOU Rotten: {:.4f}, Train_IOU Double: {:.4f}, Train_IOU Background: {:.4f},Train_F1 Score Sprout: {:.4f}, Train_F1 Score Peeled: {:.4f}, Train_F1 Score Rotten: {:.4f}, Train_F1 Score Double: {:.4f}, Train_F1 Score Background: {:.4f},Train_Precision Sprout: {:.4f},Train_Precision Peeled: {:.4f}, Train_Precision Rotten: {:.4f},Train_Precision Double: {:.4f},Train_Precision Background: {:.4f},Train_Recall Sprout: {:.4f},Train_Recall Peeled: {:.4f},Train_Recall Rotten: {:.4f},Train_Recall Double: {:.4f},Train_Recall Background: {:.4f}\".format(train_loss, train_iou_sprout, train_iou_peeled, train_iou_rotten, train_iou_double, train_iou_background,train_f1_score_sprout, train_f1_score_peeled, train_f1_score_rotten, train_f1_score_double, train_f1_score_background,train_precision_sprout, train_precision_peeled, train_precision_rotten, train_precision_double, train_precision_background,train_recall_sprout, train_recall_peeled, train_recall_rotten, train_recall_double, train_recall_background))\n",
    "\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_iou_sprout = 0.0\n",
    "    val_iou_peeled = 0.0\n",
    "    val_iou_rotten = 0.0\n",
    "    val_iou_double = 0.0\n",
    "    val_iou_background = 0.0\n",
    "    val_f1_score_sprout = 0.0\n",
    "    val_f1_score_peeled = 0.0\n",
    "    val_f1_score_rotten = 0.0\n",
    "    val_f1_score_double = 0.0\n",
    "    val_f1_score_background = 0.0\n",
    "    val_precision_sprout = 0.0\n",
    "    val_precision_peeled = 0.0\n",
    "    val_precision_rotten = 0.0\n",
    "    val_precision_double = 0.0\n",
    "    val_precision_background = 0.0\n",
    "    val_recall_sprout = 0.0\n",
    "    val_recall_peeled = 0.0\n",
    "    val_recall_rotten = 0.0\n",
    "    val_recall_double = 0.0\n",
    "    val_recall_background = 0.0\n",
    "    num_val_batches = 0\n",
    "    \n",
    "    for val_images, val_sprout_masks, val_peeled_masks, val_rotten_masks, val_double_masks, val_background_masks in val_dataset:\n",
    "        # Predict\n",
    "        val_sprout_pred, val_peeled_pred, val_rotten_pred, val_double_pred, val_background_pred = model_new(val_images, training=False)\n",
    "\n",
    "        # Compute the loss for each output\n",
    "        val_sprout_loss = sm.losses.bce_jaccard_loss(val_sprout_masks, val_sprout_pred)\n",
    "        val_peeled_loss = sm.losses.bce_jaccard_loss(val_peeled_masks, val_peeled_pred)\n",
    "        val_rotten_loss = sm.losses.bce_jaccard_loss(val_rotten_masks, val_rotten_pred)\n",
    "        val_double_loss = sm.losses.bce_jaccard_loss(val_double_masks, val_double_pred)\n",
    "        val_background_loss = sm.losses.bce_jaccard_loss(val_background_masks, val_background_pred)\n",
    "\n",
    "        # Compute total loss\n",
    "        val_total_loss = (val_sprout_loss + val_peeled_loss + val_rotten_loss + val_double_loss + val_background_loss).numpy()\n",
    "\n",
    "        # Update validation metrics\n",
    "        val_loss += val_total_loss\n",
    "        val_iou_sprout += iou_score(val_sprout_masks, val_sprout_pred)\n",
    "        val_iou_peeled += iou_score(val_peeled_masks, val_peeled_pred)\n",
    "        val_iou_rotten += iou_score(val_rotten_masks, val_rotten_pred)\n",
    "        val_iou_double += iou_score(val_double_masks, val_double_pred)\n",
    "        val_iou_background += iou_score(val_background_masks, val_background_pred)\n",
    "        \n",
    "        val_f1_score_sprout += f1_score(val_sprout_masks, val_sprout_pred)\n",
    "        val_f1_score_peeled += f1_score(val_peeled_masks, val_peeled_pred)\n",
    "        val_f1_score_rotten += f1_score(val_rotten_masks, val_rotten_pred)\n",
    "        val_f1_score_double += f1_score(val_double_masks, val_double_pred)\n",
    "        val_f1_score_background += f1_score(val_background_masks, val_background_pred)\n",
    "        \n",
    "        val_precision_sprout += precision(val_sprout_masks, val_sprout_pred)\n",
    "        val_precision_peeled += precision(val_peeled_masks, val_peeled_pred)\n",
    "        val_precision_rotten += precision(val_rotten_masks, val_rotten_pred)\n",
    "        val_precision_double += precision(val_double_masks, val_double_pred)\n",
    "        val_precision_background += precision(val_background_masks, val_background_pred)\n",
    "        \n",
    "        val_recall_sprout += recall(val_sprout_masks, val_sprout_pred)\n",
    "        val_recall_peeled += recall(val_peeled_masks, val_peeled_pred)\n",
    "        val_recall_rotten += recall(val_rotten_masks, val_rotten_pred)\n",
    "        val_recall_double += recall(val_double_masks, val_double_pred)\n",
    "        val_recall_background += recall(val_background_masks, val_background_pred)\n",
    "\n",
    "        num_val_batches += 1\n",
    "\n",
    "        if (step + 1) % 40 == 0:\n",
    "            print(\"Epoch {}/{}, Iteration {}/{} - val_Loss: {:.4f}, val_IOU Sprout: {:.4f}, val_IOU Peeled: {:.4f}, val_IOU Rotten: {:.4f}, val_IOU Double: {:.4f}, val_IOU Background: {:.4f}, val_F1 Score Sprout: {:.4f}, val_F1 Score Peeled: {:.4f}, val_F1 Score Rotten: {:.4f}, val_F1 Score Double: {:.4f}, val_F1 Score Background: {:.4f}, val_Precision Sprout: {:.4f}, val_Precision Peeled: {:.4f}, val_Precision Rotten: {:.4f}, val_Precision Double: {:.4f}, val_Precision Background: {:.4f}, val_Recall Sprout: {:.4f}, val_Recall Peeled: {:.4f}, val_Recall Rotten: {:.4f}, val_Recall Double: {:.4f}, val_Recall Background: {:.4f}\".format(epoch + 1, num_epochs, step + 1, len(train_dataset), val_loss, val_iou_sprout, val_iou_peeled, val_iou_rotten, val_iou_double, val_iou_background, val_f1_score_sprout, val_f1_score_peeled, val_f1_score_rotten, val_f1_score_double, val_f1_score_background, val_precision_sprout, val_precision_peeled, val_precision_rotten, val_precision_double, val_precision_background, val_recall_sprout, val_recall_peeled, val_recall_rotten, val_recall_double, val_recall_background))\n",
    "\n",
    "            \n",
    " \n",
    "                                    \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Calculate average validation metrics\n",
    "    val_loss /= num_val_batches\n",
    "    val_iou_sprout /= num_val_batches\n",
    "    val_iou_peeled /= num_val_batches\n",
    "    val_iou_rotten /= num_val_batches\n",
    "    val_iou_double /= num_val_batches\n",
    "    val_iou_background /= num_val_batches\n",
    "    \n",
    "    val_f1_score_sprout /= num_val_batches\n",
    "    val_f1_score_peeled /= num_val_batches\n",
    "    val_f1_score_rotten /= num_val_batches\n",
    "    val_f1_score_double /= num_val_batches\n",
    "    val_f1_score_background /= num_val_batches\n",
    "    \n",
    "    val_precision_sprout /= num_val_batches\n",
    "    val_precision_peeled /= num_val_batches\n",
    "    val_precision_rotten /= num_val_batches\n",
    "    val_precision_double /= num_val_batches\n",
    "    val_precision_background /= num_val_batches\n",
    "    \n",
    "    val_recall_sprout /= num_val_batches\n",
    "    val_recall_peeled /= num_val_batches\n",
    "    val_recall_rotten /= num_val_batches\n",
    "    val_recall_double /= num_val_batches\n",
    "    val_recall_background /= num_val_batches\n",
    "\n",
    "\n",
    "    val_losses.append(val_loss)\n",
    "    val_ious_sprout.append(val_iou_sprout)\n",
    "    val_ious_peeled.append(val_iou_peeled)\n",
    "    val_ious_rotten.append(val_iou_rotten)\n",
    "    val_ious_double.append(val_iou_double)\n",
    "    val_ious_background.append(val_iou_background)\n",
    "    \n",
    "    val_f1_scores_sprout.append(val_f1_score_sprout)\n",
    "    val_f1_scores_peeled.append(val_f1_score_peeled)\n",
    "    val_f1_scores_rotten.append(val_f1_score_rotten)\n",
    "    val_f1_scores_double.append(val_f1_score_double)\n",
    "    val_f1_scores_background.append(val_f1_score_background)\n",
    "    \n",
    "    val_precisions_sprout.append(val_precision_sprout)\n",
    "    val_precisions_peeled.append(val_precision_peeled)\n",
    "    val_precisions_rotten.append(val_precision_rotten)\n",
    "    val_precisions_double.append(val_precision_double)\n",
    "    val_precisions_background.append(val_precision_background)\n",
    "    \n",
    "    val_recalls_sprout.append(val_recall_sprout)\n",
    "    val_recalls_peeled.append(val_recall_peeled)\n",
    "    val_recalls_rotten.append(val_recall_rotten)\n",
    "    val_recalls_double.append(val_recall_double)\n",
    "    val_recalls_background.append(val_recall_background)\n",
    "\n",
    "\n",
    "\n",
    "    reduce_rl_plateau.on_epoch_end(epoch, val_loss)\n",
    "\n",
    "    current_lr = opt.learning_rate.numpy()\n",
    "    print(\"Learning Rate:\", current_lr)\n",
    "\n",
    "\n",
    "    print(\"Validation Loss: {:.4f}, Val_IOU Sprout: {:.4f}, Val_IOU Peeled: {:.4f}, Val_IOU Rotten: {:.4f}, Val_IOU Double: {:.4f}, Val_IOU Background: {:.4f}, Val_F1 Score Sprout: {:.4f}, Val_F1 Score Peeled: {:.4f}, Val_F1 Score Rotten: {:.4f}, Val_F1 Score Double: {:.4f}, Val_F1 Score Background: {:.4f}, Val_Precision Sprout: {:.4f}, Val_Precision Peeled: {:.4f}, Val_Precision Rotten: {:.4f}, Val_Precision Double: {:.4f}, Val_Precision Background: {:.4f}, Val_Recall Sprout: {:.4f}, Val_Recall Peeled: {:.4f}, Val_Recall Rotten: {:.4f}, Val_Recall Double: {:.4f}, Val_Recall Background: {:.4f}\".format(val_loss, val_iou_sprout, val_iou_peeled, val_iou_rotten, val_iou_double, val_iou_background,val_f1_score_sprout, val_f1_score_peeled, val_f1_score_rotten, val_f1_score_double, val_f1_score_background,val_precision_sprout, val_precision_peeled, val_precision_rotten, val_precision_double, val_precision_background,val_recall_sprout, val_recall_peeled, val_recall_rotten, val_recall_double, val_recall_background))\n",
    "    model_new.save(\"model_epoch_{}.h5\".format(epoch+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b3ee5-c3ed-41e4-b18a-5f43cd8a454a",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ba562-53da-4b5d-ae5f-cb09db9a3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "epochs = range(1, num_epochs + 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597f9c0c-02ab-48af-b6cb-642874204593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_ious_sprout, label='Training IOU Sprout')\n",
    "plt.plot(epochs, val_ious_sprout, label='Validation IOU Sprout')\n",
    "plt.title('IOU for Sprout per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f035eb-10e3-486a-a02a-a0eba2e1fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_ious_peeled, label='Training IOU Peeled')\n",
    "plt.plot(epochs, val_ious_peeled, label='Validation IOU Peeled')\n",
    "plt.title('IOU for Peeled per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b62c401-6326-44d8-acb8-884cbc839823",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_ious_rotten, label='Training IOU Rotten')\n",
    "plt.plot(epochs, val_ious_rotten, label='Validation IOU Rotten')\n",
    "plt.title('IOU for Rotten per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d8316-697b-4275-acda-42bd3d090a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_ious_double, label='Training IOU Double')\n",
    "plt.plot(epochs, val_ious_double, label='Validation IOU Double')\n",
    "plt.title('IOU for Double per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616bed31-42c6-439c-8d6a-124e44d3c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_ious_background, label='Training IOU Background')\n",
    "plt.plot(epochs, val_ious_background, label='Validation IOU Background')\n",
    "plt.title('IOU for Background per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19620a79-ca02-4b9e-8b48-d11e694ba691",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_precisions_sprout, label='Training Precision Sprout')\n",
    "plt.plot(epochs, val_precisions_sprout, label='Validation Precision Sprout')\n",
    "plt.title('Precision for Sprout per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41e0a7-9c4f-4fe5-a17c-8a68a01e2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_precisions_peeled, label='Training Precision Peeled')\n",
    "plt.plot(epochs, val_precisions_peeled, label='Validation Precision Peeled')\n",
    "plt.title('Precision for Peeled per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2602e-e385-4eb8-b2a4-09dc254a4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_precisions_rotten, label='Training Precision Rotten')\n",
    "plt.plot(epochs, val_precisions_rotten, label='Validation Precision Rotten')\n",
    "plt.title('Precision for Rotten per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0263a-fcce-4b10-ac57-5d8865c6052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_precisions_double, label='Training Precision Double')\n",
    "plt.plot(epochs, val_precisions_double, label='Validation Precision Double')\n",
    "plt.title('Precision for double per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9a735-4f2d-4b46-8630-49162931525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_precisions_background, label='Training Precision Background')\n",
    "plt.plot(epochs, val_precisions_background, label='Validation Precision Background')\n",
    "plt.title('Precision for Background per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559877fb-1a85-4c12-b2a1-70f01930c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_recalls_sprout, label='Training Recall Sprout')\n",
    "plt.plot(epochs, val_recalls_sprout, label='Validation Recall Sprout')\n",
    "plt.title('Recall for Sprout per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f8489-fdff-43cc-a974-4b15a6f52937",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_recalls_peeled, label='Training Recall Peeled')\n",
    "plt.plot(epochs, val_recalls_peeled, label='Validation Recall Peeled')\n",
    "plt.title('Recall for Peeled per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f0c6a-ed81-453c-8f42-e943e5f5bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_recalls_rotten, label='Training Recall Rotten')\n",
    "plt.plot(epochs, val_recalls_rotten, label='Validation Recall Rotten')\n",
    "plt.title('Recall for Rotten per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07adcbb-1325-456c-81da-bedff2ecfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_recalls_double, label='Training Recall Double')\n",
    "plt.plot(epochs, val_recalls_double, label='Validation Recall Double')\n",
    "plt.title('Recall for Double per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe16d84-b039-40e6-ac12-8f0cb22f011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_recalls_background, label='Training Recall Background')\n",
    "plt.plot(epochs, val_recalls_background, label='Validation Recall Background')\n",
    "plt.title('Recall for Background per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9304a-d915-41bb-ada5-7c11b6f03033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_f1_scores_sprout, label='Training F1 Score Sprout')\n",
    "plt.plot(epochs, val_f1_scores_sprout, label='Validation F1 Score Sprout')\n",
    "plt.title('F1 Score for Sprout per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cb70f5-6c5e-4d3d-a3e8-958de711edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_f1_scores_peeled, label='Training F1 Score Peeled')\n",
    "plt.plot(epochs, val_f1_scores_peeled, label='Validation F1 Score Peeled')\n",
    "plt.title('F1 Score for Peeled per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cdf6b-aaeb-4af3-a07b-b0bd53db2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_f1_scores_rotten, label='Training F1 Score Rotten')\n",
    "plt.plot(epochs, val_f1_scores_rotten, label='Validation F1 Score Rotten')\n",
    "plt.title('F1 Score for Rotten per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4d546-1029-4874-9a3b-f3695fc0d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_f1_scores_double, label='Training F1 Score double')\n",
    "plt.plot(epochs, val_f1_scores_double, label='Validation F1 Score double')\n",
    "plt.title('F1 Score for Double per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84785d5f-39ba-401d-902d-defd7d57333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_f1_scores_background, label='Training F1 Score Background')\n",
    "plt.plot(epochs, val_f1_scores_background, label='Validation F1 Score Background')\n",
    "plt.title('F1 Score for Background per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b54789-4b57-4abb-82ae-e3d5decc9c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523cc89-d259-4a50-a75d-2853c52b5426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bfe29-27aa-4cbb-8763-783f301db882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001dc4e-fb90-4bfe-8bd5-9eee54ccc4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5af530-6e7e-4908-90c0-43abd927d06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017b49f-6683-4a91-b36e-a755e90aa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474634d-634b-47de-8a8c-8093a6c0c3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddebca31-5072-4eaa-aa88-8107d54bd8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm as tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "import segmentation_models as sm\n",
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.utils import generic_utils\n",
    "from segmentation_models.losses import CategoricalFocalLoss\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
    "# from keras.optimizers import Adam,SGD\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.metrics import MeanIoU\n",
    "from glob import glob\n",
    "\n",
    "def preprocessMasks(mask,height,width):\n",
    "    mask_resized = cv2.threshold(cv2.resize(mask, (height,width)), 50, 1, cv2.THRESH_BINARY)[1]\n",
    "    mask_data = np.zeros((height,width,2))\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "\n",
    "\n",
    "            #for segmentation mask\n",
    "            if mask_resized[i,j]> 0:\n",
    "                mask_data[i,j,1] = 1\n",
    "            else:\n",
    "                mask_data[i,j,0] = 1\n",
    "                \n",
    "    return mask_data       #output from the function(height, width, 2)\n",
    "def load_data(path):\n",
    "    images = sorted(glob(os.path.join(image_path, 'images/*')))\n",
    "    sprout = sorted(glob(os.path.join(image_path, 'Sprout/*')))\n",
    "    peeled = sorted(glob(os.path.join(image_path, 'Peeled/*')))\n",
    "    rotten = sorted(glob(os.path.join(image_path, 'Rotten/*')))\n",
    "    double = sorted(glob(os.path.join(image_path, 'Double/*')))\n",
    "    background = sorted(glob(os.path.join(image_path, 'Background/*')))\n",
    "    return images,sprout,peeled,rotten,double,background\n",
    "    \n",
    "image_path = '/home/agrograde/Desktop/4th_mar/image_path'\n",
    "images,sprout,peeled,rotten,double,background = load_data(image_path)\n",
    "def read_image(path):\n",
    "    \n",
    "    x = cv2.imread(path)\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "    \n",
    "def read_mask(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = preprocessMasks(x, 224, 224)\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "    \n",
    "    x = read_image(images[0])\n",
    "y1 = read_mask(sprout[0])\n",
    "y2 = read_mask(peeled[0])\n",
    "y3 = read_mask(rotten[0])\n",
    "y4 = read_mask(double[0])\n",
    "y5 = read_mask(background[0])\n",
    "def preprocess(x,y1,y2,y3,y4,y5):\n",
    "    def f(x,y1,y2,y3,y4,y5):\n",
    "        x = x.decode()\n",
    "        y1 = y1.decode()\n",
    "        y2 = y2.decode()\n",
    "        y3 = y3.decode()\n",
    "        y4 = y4.decode()\n",
    "        y5 = y5.decode()\n",
    "        \n",
    "        x = read_image(x)\n",
    "        y1 = read_mask(y1)\n",
    "        y2 = read_mask(y2)\n",
    "        y3 = read_mask(y3)\n",
    "        y4 = read_mask(y4)\n",
    "        y5 = read_mask(y5)\n",
    "        \n",
    "        return x,y1,y2,y3,y4,y5\n",
    "    \n",
    "    images, sprout, peeled, rotten,double,background = tf.numpy_function(f, [x,y1,y2,y3,y4,y5], [tf.float32, tf.float32,tf.float32,tf.float32,tf.float32,tf.float32])\n",
    "    images.set_shape([224, 224, 3])\n",
    "    sprout.set_shape([224, 224, 2])\n",
    "    peeled.set_shape([224, 224, 2])\n",
    "    rotten.set_shape([224, 224, 2])\n",
    "    double.set_shape([224, 224, 2])\n",
    "    background.set_shape([224, 224, 2])\n",
    "\n",
    "    return images, sprout, peeled, rotten,double, background\n",
    "\n",
    "def tf_dataset(x, y1, y2, y3, y4, y5, batch_size, train_split=0.8, val_split=0.1):\n",
    "    # Combine inputs and targets into a single dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y1, y2, y3, y4, y5))\n",
    "    \n",
    "    # Shuffle the dataset with a buffer size of 1000\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "    \n",
    "    # Apply any necessary preprocessing to each sample (e.g., normalization, resizing)\n",
    "    dataset = dataset.map(preprocess)\n",
    "    \n",
    "    # Calculate the number of samples for each split\n",
    "    total_samples = len(x)\n",
    "    train_samples = int(total_samples * train_split)\n",
    "    val_samples = int(total_samples * val_split)\n",
    "    \n",
    "    # Split dataset into training and validation sets\n",
    "    train_dataset = dataset.take(train_samples)\n",
    "    val_dataset = dataset.skip(train_samples).take(val_samples)\n",
    "    \n",
    "    # Split inputs and targets into separate datasets\n",
    "    train_images = train_dataset.map(lambda x, *y: x)\n",
    "    train_sprout = train_dataset.map(lambda x, *y: y[0])\n",
    "    train_peeled = train_dataset.map(lambda x, *y: y[1])\n",
    "    train_rotten = train_dataset.map(lambda x, *y: y[2])\n",
    "    train_double = train_dataset.map(lambda x, *y: y[3])\n",
    "    train_background = train_dataset.map(lambda x, *y: y[4])\n",
    "    \n",
    "    # For validation dataset\n",
    "    val_images = val_dataset.map(lambda x, *y: x)\n",
    "    val_sprout = val_dataset.map(lambda x, *y: y[0])\n",
    "    val_peeled = val_dataset.map(lambda x, *y: y[1])\n",
    "    val_rotten = val_dataset.map(lambda x, *y: y[2])\n",
    "    val_double = val_dataset.map(lambda x, *y: y[3])\n",
    "    val_background = val_dataset.map(lambda x, *y: y[4])\n",
    "    \n",
    "    # Batch the datasets\n",
    "    train_images = train_images.batch(batch_size)\n",
    "    train_sprout = train_sprout.batch(batch_size)\n",
    "    train_peeled = train_peeled.batch(batch_size)\n",
    "    train_rotten = train_rotten.batch(batch_size)\n",
    "    train_double = train_double.batch(batch_size)\n",
    "    train_background = train_background.batch(batch_size)\n",
    "    \n",
    "    val_images = val_images.batch(batch_size)\n",
    "    val_sprout = val_sprout.batch(batch_size)\n",
    "    val_peeled = val_peeled.batch(batch_size)\n",
    "    val_rotten = val_rotten.batch(batch_size)\n",
    "    val_double = val_double.batch(batch_size)\n",
    "    val_background = val_background.batch(batch_size)\n",
    "    \n",
    "    # Prefetch data for improved performance\n",
    "    train_images = train_images.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_sprout = train_sprout.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_peeled = train_peeled.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_rotten = train_rotten.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_double = train_double.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    train_background = train_background.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_images = val_images.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_sprout = val_sprout.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_peeled = val_peeled.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_rotten = val_rotten.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_double = val_double.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_background = val_background.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return (train_images, train_sprout, train_peeled, train_rotten, train_double, train_background), \\\n",
    "           (val_images, val_sprout, val_peeled, val_rotten, val_double, val_background)\n",
    "\n",
    "(train_images, train_sprout, train_peeled, train_rotten, train_double, train_background), \\\n",
    "(val_images, val_sprout, val_peeled, val_rotten, val_double, val_background) = \\\n",
    "    tf_dataset(images, sprout, peeled, rotten, double, background, batch_size=16, \n",
    "               train_split=0.8, val_split=0.1)\n",
    "#main utility functions for model\n",
    "def dsc(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dsc(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def iou_score(gt, pr, class_weights=1., smooth=1, per_image=True, threshold=None):\n",
    "    '''\n",
    "    input：\n",
    "        gt: ground truth 4D keras tensor (B, H, W, C)\n",
    "        pr: prediction 4D keras tensor (B, H, W, C)\n",
    "        class_weights: 1. or list of class weights, len(weights) = C\n",
    "        smooth: value to avoid division by zero\n",
    "        per_image: if ``True``, metric is calculated as mean over images in batch (B),\n",
    "            else over whole batch\n",
    "        threshold: value to round predictions (use ``>`` comparison), \n",
    "        if ``None`` prediction prediction will not be round\n",
    "    output：\n",
    "        IoU/Jaccard score in range [0, 1]\n",
    "    '''\n",
    "    if per_image:\n",
    "        axes = [1, 2]\n",
    "    else:\n",
    "        axes = [0, 1, 2]\n",
    "        \n",
    "    if threshold is not None:\n",
    "        pr = tf.greater(pr, threshold)\n",
    "        pr = tf.cast(pr, dtype=tf.float32)\n",
    "\n",
    "    intersection = tf.reduce_sum(gt * pr, axis=axes)\n",
    "    union = tf.reduce_sum(gt + pr, axis=axes) - intersection\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "\n",
    "    # mean per image\n",
    "    if per_image:\n",
    "        iou = tf.reduce_mean(iou, axis=0)\n",
    "\n",
    "    # weighted mean per class\n",
    "    iou = tf.reduce_mean(iou * class_weights)\n",
    "\n",
    "    return iou\n",
    "#build model\n",
    "import segmentation_models as sm\n",
    "from keras.layers import *\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def SEModule(input, ratio, out_dim):\n",
    "    # bs, c, h, w\n",
    "    x = GlobalAveragePooling2D()(input)\n",
    "    excitation = Dense(units=out_dim // ratio)(x)\n",
    "    excitation = Activation('relu')(excitation)\n",
    "    excitation = Dense(units=out_dim)(excitation)\n",
    "    excitation = Activation('sigmoid')(excitation)\n",
    "    excitation = Reshape((1, 1, out_dim))(excitation)\n",
    "    scale = multiply([input, excitation])\n",
    "    return scale\n",
    "\n",
    "\n",
    "def SEUnet(nClasses, input_height=224, input_width=224):\n",
    "    inputs = Input(shape=(input_height, input_width, 3))\n",
    "    conv1 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "\n",
    "    conv1 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "\n",
    "    # se\n",
    "    conv1 = SEModule(conv1, 4, 16)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "\n",
    "    conv2 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "\n",
    "    # se\n",
    "    conv2 = SEModule(conv2, 8, 32)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    conv3 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    # se\n",
    "    conv3 = SEModule(conv3, 8, 64)\n",
    "\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    conv4 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    # se\n",
    "    conv4 = SEModule(conv4, 16, 128)\n",
    "\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(256,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(256,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    # se\n",
    "    conv5 = SEModule(conv5, 16, 256)\n",
    "\n",
    "    up6 = Conv2D(128,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv5))\n",
    "    up6 = BatchNormalization()(up6)\n",
    "\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    conv6 = Conv2D(128,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    # se\n",
    "    conv6 = SEModule(conv6, 16, 128)\n",
    "\n",
    "    up7 = Conv2D(64,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv6))\n",
    "    up7 = BatchNormalization()(up7)\n",
    "\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    conv7 = Conv2D(64,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    # se\n",
    "    conv7 = SEModule(conv7, 8, 64)\n",
    "\n",
    "    up8 = Conv2D(32,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv7))\n",
    "    up8 = BatchNormalization()(up8)\n",
    "\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    conv8 = Conv2D(32,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    # se\n",
    "    conv8 = SEModule(conv8, 4, 32)\n",
    "\n",
    "    up9 = Conv2D(16,\n",
    "                 2,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(UpSampling2D(size=(2,\n",
    "                                                                    2))(conv8))\n",
    "    up9 = BatchNormalization()(up9)\n",
    "\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    conv9 = Conv2D(16,\n",
    "                   3,\n",
    "                   activation='relu',\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    # se\n",
    "    conv9 = SEModule(conv9, 2, 16)\n",
    "\n",
    "    conv10 = Conv2D(nClasses, (3, 3), padding='same')(conv9)\n",
    "    conv10 = BatchNormalization()(conv10)\n",
    "\n",
    "    outputHeight = Model(inputs, conv10).output_shape[1]\n",
    "    outputWidth = Model(inputs, conv10).output_shape[2]\n",
    "\n",
    "    out = (Reshape((outputHeight * outputWidth, nClasses)))(conv10)\n",
    "    out = Activation('softmax')(out)\n",
    "\n",
    "    model = Model(inputs,out)\n",
    "    model.outputHeight = outputHeight\n",
    "    model.outputWidth = outputWidth\n",
    "\n",
    "    return model\n",
    "\n",
    "model1 = SEUnet(nClasses=5)\n",
    "model1.summary()\n",
    "x = model1.get_layer(index=-3).output\n",
    "\n",
    "# folder=[\"Sprout\",\"Black_smut\",\"Rotten\",\"Background\"]\n",
    "out0 = Conv2D(2, (1, 1), activation='softmax',name='sprout')(x)\n",
    "out1 = Conv2D(2, (1, 1), activation='softmax',name='peeled')(x)\n",
    "out2 = Conv2D(2, (1, 1), activation='softmax',name='rotten')(x)\n",
    "out3 = Conv2D(2, (1, 1), activation='softmax',name='double')(x)\n",
    "out4 = Conv2D(2, (1, 1), activation='softmax',name='background')(x)\n",
    "\n",
    "\n",
    "model_new = Model(inputs = model1.input,outputs = [out0,out1,out2,out3,out4])\n",
    "model_new.summary()\n",
    "from segmentation_models.metrics import  f1_score,precision,recall\n",
    "from segmentation_models.metrics import  f1_score\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model_name = 'onin_24th_jan_spplrobg'\n",
    "date = '24thdec2024'\n",
    "learning_rate = 0.001\n",
    "# num_epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the optimizer\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "# Define losses, metrics, and loss weights\n",
    "losses = {\"sprout\": sm.losses.bce_jaccard_loss, \"peeled\": sm.losses.bce_jaccard_loss, \"rotten\": sm.losses.bce_jaccard_loss,\"double\": sm.losses.bce_jaccard_loss,\"background\": sm.losses.bce_jaccard_loss}\n",
    "metrics = {\"sprout\": [iou_score, f1_score,precision,recall], \"peeled\": [iou_score, f1_score,precision,recall], \"rotten\": [iou_score, f1_score,precision,recall],\"double\": [iou_score, f1_score,precision,recall], \"background\": [iou_score, f1_score,precision,recall]}\n",
    "loss_weights = {\"sprout\": 1.0, \"peeled\": 1.0, \"rotten\": 1.0, \"double\": 1.0, \"background\": 2.0}\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "\n",
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "LR_Reduce_callback = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10, verbose=1, mode='auto')\n",
    "model_ckpt1 = ModelCheckpoint(model_name+'_'+date+'.h5', monitor='loss', save_weights_only=False,save_best_only=True, period=1)\n",
    "model_ckpt2 = ModelCheckpoint(model_name+'_'+date+'_weights.h5', monitor='loss', save_weights_only=True,save_best_only=True, period=1)\n",
    "# reduce_rl_plateau = CustomReduceLRoP(patience=4, \n",
    "#                               verbose=1, \n",
    "#                               optim_lr=opt.learning_rate, \n",
    "#                               mode='auto',\n",
    "#                               factor=0.1)\n",
    "# Compile the model using the initialized optimizer\n",
    "model_new.compile(optimizer=opt, loss=losses, metrics=metrics)\n",
    "labels_dict = {\n",
    "    \"sprout\": train_sprout,\n",
    "    \"peeled\": train_peeled,\n",
    "    \"rotten\": train_rotten,\n",
    "    \"double\": train_double,\n",
    "    \"background\": train_background\n",
    "}\n",
    "val_labels_dict = {\n",
    "    \"sprout\": val_sprout,\n",
    "    \"peeled\": val_peeled,\n",
    "    \"rotten\": val_rotten,\n",
    "    \"double\": val_double,\n",
    "    \"background\": val_background\n",
    "}\n",
    "val_data = tf.data.Dataset.zip((val_images, val_labels_dict)) \n",
    "# Zip images and label dictionary into a single dataset\n",
    "train_data = tf.data.Dataset.zip((train_images, labels_dict))\n",
    "\n",
    "H = model_new.fit(train_data,\n",
    "                  epochs=2,\n",
    "                  validation_data=val_data,\n",
    "                  callbacks=[tensorboard_callback, LR_Reduce_callback, model_ckpt1, model_ckpt2],\n",
    "                  batch_size=16)\n",
    "\n",
    "\n",
    "is there any issues in the data pipelines and data loader and training ...cuz accuracy is not being increased in this pipeline and please confirm me that is it like every time new batch of data is being uploaded or same batch is being repeated ....in every epochs the whole dtaasets should be repeated...where is the issue why the accuracy is not being increased even after 5k data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_data(images, masks):\n",
    "    fig, axs = plt.subplots(1, 6, figsize=(15, 5))\n",
    "    axs[0].imshow(images[0].numpy().astype(\"uint8\"))\n",
    "    axs[0].set_title(\"Image\")\n",
    "    \n",
    "    mask_titles = [\"Sprout\", \"Peeled\", \"Rotten\", \"Double\", \"Background\"]\n",
    "    \n",
    "    for i in range(5):\n",
    "        axs[i+1].imshow(masks[i][0].numpy().astype(\"uint8\"), cmap=\"gray\")\n",
    "        axs[i+1].set_title(mask_titles[i])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of data\n",
    "for batch_images, batch_masks in train_data.take(1):\n",
    "    visualize_data(batch_images, [batch_masks[\"sprout\"], batch_masks[\"peeled\"], batch_masks[\"rotten\"], batch_masks[\"double\"], batch_masks[\"background\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
